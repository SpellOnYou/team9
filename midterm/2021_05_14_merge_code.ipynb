{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_2021_05_12_merge_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zwxJN-alkO9V",
        "qAr2ogy3sLeW",
        "gRWgXS_wvonM",
        "oT7n4bqFvsa9",
        "Loh79wNZwS_o",
        "i4aEwhi9BjoL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpellOnYou/CLab21/blob/main/midterm/2021_05_14_merge_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxJN-alkO9V"
      },
      "source": [
        "## Enviroment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k232czaeCGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34d4693f-2555-44e8-fe40-465e2a48a503"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/CLab21.git'.format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: SpellOnYou\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAr2ogy3sLeW"
      },
      "source": [
        "## Pre-processing(text representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9HpXhzDALSn"
      },
      "source": [
        "Comment\n",
        "\n",
        "1. Generally don't need to use external library to read csv. open() function will work.\n",
        "2. Now we read one file twice(1. for sentence padding, 2. one-hot encoding) --> not efficient way to use computation resource :) should consider reconstructuring data loading process.\n",
        "3. Didn't investigate the whole algorithm. But BOW took much time compared to its data size. Need to be checked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRWgXS_wvonM"
      },
      "source": [
        "### x data, tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woGbW17CslSY"
      },
      "source": [
        "class PadMaxLength:\n",
        "\n",
        "    def __init__(self, file_name):\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.list_padded_sentences = []\n",
        "        self.text = []\n",
        "        for col in self.csv_file:\n",
        "            self.text.append(col[\"text\"])\n",
        "\n",
        "    def min_max_sentences(self):\n",
        "        tokenized_sentences = []\n",
        "        # split each sentence into words\n",
        "        for sentence in self.text:\n",
        "            tokens = sentence.split()\n",
        "            tokenized_sentences.append(tokens)\n",
        "        # get longest sentence and its length\n",
        "        longest_sent = max(tokenized_sentences, key=len)\n",
        "        longest_sent_len = len(longest_sent)\n",
        "\n",
        "        # get shortest word and its length\n",
        "        shortest_sent = min(tokenized_sentences, key=len)\n",
        "        shortest_sent_len = len(shortest_sent)\n",
        "\n",
        "        return longest_sent_len, shortest_sent_len\n",
        "\n",
        "    def right_pad_sentences(self, max_sent_length):\n",
        "        max_len = round(max_sent_length * 0.50)  # Take 50% of the maximum sentence length to avoid sparsity\n",
        "        padded_sentences = []\n",
        "        # print(max_len)\n",
        "\n",
        "        for sentence in self.text:\n",
        "            sentence = sentence.strip()\n",
        "            sentence = sentence.split()\n",
        "\n",
        "            if len(sentence) > max_len:\n",
        "                a = sentence[:max_len]  # discard tokens longer than max_length\n",
        "                padded_sentences.append(a)\n",
        "\n",
        "            elif len(sentence) < max_len:\n",
        "                [sentence.append(\"0\") for i in\n",
        "                 range(max_len - len(sentence))]  # pad sentences with zeros smaller than max_length\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "            else:\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "        for pad_sent in padded_sentences:\n",
        "            list_sentences = ' '.join(pad_sent)\n",
        "            self.list_padded_sentences.append(list_sentences)\n",
        "\n",
        "        return self.list_padded_sentences\n",
        "\n",
        "    def merge_with(self, list2, list3):\n",
        "        merged = self.list_padded_sentences + list2 + list3\n",
        "        return merged"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS7wfoe__X-_"
      },
      "source": [
        "\n",
        "class BagOfWords:\n",
        "\n",
        "    def __init__(self, all_padded_sentences, list_of_sentences):\n",
        "\n",
        "        # define punctuation and upper case alphabet\n",
        "        self.punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "        self.upper = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "        self.vocab = self.generate_vocabulary(all_padded_sentences)  # Generate the vocabulary\n",
        "        #print(len(self.vocab))\n",
        "        self.dict_idx = self.indexing(self.vocab)  # Generate the indexing\n",
        "        self.word_count = self.count_dictionary(list_of_sentences)\n",
        "        self.N_sentences = len(list_of_sentences)\n",
        "\n",
        "    def lowercase_tokenize(self, padded_sentences):\n",
        "        lowercase = \"\"\n",
        "        for char in padded_sentences:\n",
        "            if char in self.upper:\n",
        "                k = ord(char)\n",
        "                l = k + 32\n",
        "                lowercase = lowercase + (chr(l))\n",
        "            elif char in self.punctuations:\n",
        "                continue\n",
        "            else:\n",
        "                lowercase = lowercase + char\n",
        "        lowercase = lowercase.strip()\n",
        "        tokenized = list(lowercase.split())\n",
        "        return tokenized\n",
        "\n",
        "    def generate_vocabulary(self, all_padded_sentences):\n",
        "        vocab = []\n",
        "        for sentence in all_padded_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            for word in tokenized_sentence:  # append only unique words\n",
        "                if word not in vocab:\n",
        "                    vocab.append(word)\n",
        "        return vocab\n",
        "\n",
        "    def indexing(self, tokens):\n",
        "        # Index dictionary to assign an index to each word in vocabulary\n",
        "        index_word = {}\n",
        "        i = 0\n",
        "        for word in tokens:\n",
        "            index_word[word] = i\n",
        "            i += 1\n",
        "        return index_word\n",
        "\n",
        "    def count_dictionary(self, input_sentences):\n",
        "        word_count = {}\n",
        "        for word in self.vocab:\n",
        "            word_count[word] = 0.0\n",
        "            for sentence in input_sentences:\n",
        "                if word in sentence:\n",
        "                    word_count[word] += 1.0\n",
        "        return word_count\n",
        "\n",
        "    # Term Frequency\n",
        "    def termfreq(self, sentence, word):\n",
        "        number_of_sentences = float(len(sentence))\n",
        "        occurrence = float(len([token for token in sentence if token == word]))\n",
        "        return occurrence / number_of_sentences\n",
        "\n",
        "    def inverse_doc_freq(self, word):\n",
        "        try:\n",
        "            word_occurrence = self.word_count[word] + 1.0\n",
        "        except KeyError:\n",
        "            word_occurrence = 1.0\n",
        "        return np.log(self.N_sentences / word_occurrence)\n",
        "\n",
        "    def tf_idf(self, input_sentences):\n",
        "        row = 0\n",
        "        tf_idf_vec = np.zeros((self.N_sentences, (len(self.vocab))))\n",
        "\n",
        "        for sentence in input_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            for word in tokenized_sentence:\n",
        "                tf = self.termfreq(sentence, word)\n",
        "                idf = self.inverse_doc_freq(word)\n",
        "\n",
        "                value = tf * idf\n",
        "                tf_idf_vec[row][self.dict_idx[word]] = value\n",
        "\n",
        "            row += 1\n",
        "\n",
        "        return tf_idf_vec\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXCuQpTO_f53"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT7n4bqFvsa9"
      },
      "source": [
        "### y data, one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDRL76A2vwK5"
      },
      "source": [
        "# from data_preprocessing.OneHotEncoding import *\n",
        "class OneHotEncoding:\n",
        "    def __init__(self, file_name):\n",
        "        self.mapping_dict = {}\n",
        "        #self.csv_file = pd.read_csv(file_name)\n",
        "        #self.labels = self.csv_file[\"label\"]\n",
        "\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.labels = []\n",
        "        for col in self.csv_file:\n",
        "            self.labels.append(col[\"label\"])\n",
        "\n",
        "        self.target_labels = []\n",
        "        for word in self.labels:\n",
        "            if word not in self.target_labels:\n",
        "                self.target_labels.append(word)\n",
        "\n",
        "        #self.target_labels = self.labels.unique()\n",
        "        self.labels_dict = {}\n",
        "        self.mapping()\n",
        "\n",
        "    def get_unique_labels(self):\n",
        "\n",
        "        return self.target_labels\n",
        "\n",
        "    def mapping(self):\n",
        "        ### map each emotion to an integer\n",
        "        one_hot_encoded = []\n",
        "        for label_idx in range(len(self.target_labels)):\n",
        "            self.mapping_dict[self.target_labels[label_idx]] = label_idx\n",
        "        #print(self.mapping_dict)\n",
        "\n",
        "        for c in self.target_labels:\n",
        "            arr = list(np.zeros(len(self.target_labels), dtype=int))\n",
        "            arr[self.mapping_dict[c]] = 1\n",
        "            one_hot_encoded.append(arr)\n",
        "\n",
        "        self.generate_dictionary(one_hot_encoded)\n",
        "\n",
        "        return one_hot_encoded\n",
        "\n",
        "    def generate_dictionary(self, one_hot_encoded):\n",
        "        self.labels_dict = dict(zip(self.target_labels, one_hot_encoded))  # universal dict\n",
        "\n",
        "    def one_hot_encoding(self, encoded_dict=None):\n",
        "        df_labels = []\n",
        "        if encoded_dict is None:\n",
        "            encoded_dict = self.labels_dict\n",
        "        for c in self.labels:\n",
        "            if c in encoded_dict.keys():\n",
        "                df_labels.append(encoded_dict[c])\n",
        "        return np.array(df_labels)\n",
        "\n",
        "    def get_encoded_dict(self):\n",
        "        return self.labels_dict"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgy4Z0ye_tE2"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loh79wNZwS_o"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ckMvLZvF2Q"
      },
      "source": [
        "class Linear():\n",
        "    def __init__(self, w, b):\n",
        "        self.w, self.b = w, b\n",
        "    def forward(self, x): \n",
        "        self.inp = x\n",
        "        self.out = self.inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        # set_trace()\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)\n",
        "\n",
        "\n",
        "class Relu():\n",
        "    def forward(self, x):\n",
        "        self.inp = x\n",
        "        self.out = x.clamp_min(0.) - 0.5\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g* (self.inp>0).float()\n",
        "\n",
        "class CrossEntropy():\n",
        "    def __call__(self, pred, y):\n",
        "        \n",
        "        self.yhat, self.y = pred, y\n",
        "        self.out = self.nll(self.log_softmax(pred), y)\n",
        "        \n",
        "        return self.out\n",
        "\n",
        "    def nll(self, pred, y):\n",
        "        # print(pred.shape, y.shape)\n",
        "        return -pred[range(y.shape[0]), y.max(-1).indices].mean()\n",
        "\n",
        "    def log_softmax(self, x): return x - x.exp().sum(-1,keepdim=True).log()\n",
        "\n",
        "    def backward(self):\n",
        "        self.yhat.g = (self.yhat.exp()/(self.yhat.exp().sum(-1,keepdim=True))) - self.y\n",
        "\n",
        "class Mse():\n",
        "    def __call__(self, yhat, y):\n",
        "        # set_trace()\n",
        "        self.yhat, self.y = yhat, y\n",
        "        self.out = (yhat.squeeze(-1) - y).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.yhat.g = 2. * (self.yhat.squeeze() - self.y).unsqueeze(-1) / self.y.shape[0]\n",
        "\n",
        "class DummyModel():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.loss = CrossEntropy()\n",
        "        self.layers = [Linear(w1,b1), Relu(), Linear(w2, b2)]\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "\n",
        "        for layer in self.layers:\n",
        "            \n",
        "            x = layer.forward(x)\n",
        "        self.out = x\n",
        "        return self.loss(self.out, self.y)\n",
        "\n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for layer in reversed(self.layers):\n",
        "            # set_trace()\n",
        "            layer.backward()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4aEwhi9BjoL"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qdw_z2jsh02",
        "outputId": "6f32311e-a6fd-425c-8683-2ba789296809"
      },
      "source": [
        "%cd /content/CLab21/"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CLab21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EWlD51R_68gY"
      },
      "source": [
        "# # in case you need debug\n",
        "# !pip install -q ipdb\n",
        "# from ipdb import set_trace"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqfMvzIJ--Qz"
      },
      "source": [
        "import numpy as np\n",
        "import csv, math\n",
        "from torch import tensor, float32, randn, no_grad"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi-LbQsQdngW"
      },
      "source": [
        "from pathlib import Path\n",
        "rpath = Path('/content/CLab21/data/emotions')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Qh2Pe1sdFz"
      },
      "source": [
        "train_file = rpath/\"isear/isear-train-modified.csv\"\n",
        "val_file = rpath/\"isear/isear-val-modified.csv\"\n",
        "test_file = rpath/\"isear/isear-test-modified.csv\""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFXXMSNILzWK"
      },
      "source": [
        "- padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfnFBqGSLU7P",
        "outputId": "5c3cf612-4875-4fcb-87a3-656ad5e92f46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%timeit\n",
        "pml_train = PadMaxLength(train_file)\n",
        "pml_val = PadMaxLength(val_file)\n",
        "pml_test = PadMaxLength(test_file)\n",
        "\n",
        "max_sent, min_sent = pml_train.min_max_sentences()\n",
        "\n",
        "sentences_padded_train = pml_train.right_pad_sentences(max_sent)\n",
        "sentences_padded_val = pml_val.right_pad_sentences(max_sent)\n",
        "sentences_padded_test = pml_test.right_pad_sentences(max_sent)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 5: 115 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkbLH5cL2x9"
      },
      "source": [
        "- vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBy365HgL1E4"
      },
      "source": [
        "%timeit\n",
        "vocab_list = pml_train.merge_with(sentences_padded_val, sentences_padded_test)  # Vocab over all files\n",
        "\n",
        "bow_train = BagOfWords(vocab_list, sentences_padded_train)  # Sentences to create the vocabulary\n",
        "bow_val = BagOfWords(vocab_list, sentences_padded_val)\n",
        "bow_test = BagOfWords(vocab_list, sentences_padded_test)\n",
        "\n",
        "tf_idf_train = bow_train.tf_idf(sentences_padded_train)\n",
        "tf_idf_val = bow_val.tf_idf(sentences_padded_val)\n",
        "tf_idf_test = bow_test.tf_idf(sentences_padded_test)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0PzRMeQMF_9"
      },
      "source": [
        "- y data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eXy6viABoQI"
      },
      "source": [
        "ohe_train = OneHotEncoding(train_file)\n",
        "ohe_val = OneHotEncoding(val_file)\n",
        "ohe_test = OneHotEncoding(test_file)\n",
        "\n",
        "y_train = ohe_train.one_hot_encoding()\n",
        "reference_dict = ohe_train.get_encoded_dict()\n",
        "\n",
        "y_val = ohe_val.one_hot_encoding(reference_dict)\n",
        "y_test = ohe_test.one_hot_encoding(reference_dict)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeZelBjOMJke"
      },
      "source": [
        "- torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE8tNCSTwkfm"
      },
      "source": [
        "train_x, train_y = tensor(tf_idf_train, dtype=float32), tensor(y_train)\n",
        "valid_x, valid_y = tensor(tf_idf_val, dtype=float32), tensor(y_val)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU_2O7HYnsG9",
        "outputId": "07514078-81cc-496b-e24e-1cfbc003f2f0"
      },
      "source": [
        "train_x.shape, valid_x.shape"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5344, 9355]), torch.Size([1148, 9355]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRwKN6JhCdEh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCGjqTKMohOR"
      },
      "source": [
        "train_x = train_x[:, :3000]\n",
        "valid_x = valid_x[:, :3000]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZBx1tYwcke"
      },
      "source": [
        "#n: data size m: n_text_feature h: hidden node c: out node\n",
        "n, m, h, c = *train_x.shape, 100, train_y.shape[1]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqSePVr9yNTq"
      },
      "source": [
        "w1 = randn(m, h) / math.sqrt(h)\n",
        "w2 = randn(h, c)\n",
        "b1 = randn(h)\n",
        "b2 = randn(c)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjpCwynUydkR"
      },
      "source": [
        "model = DummyModel(w1, b1, w2, b2)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZZVUjYc8187",
        "outputId": "8bda456f-232e-4972-c69b-150cbb56e3ff"
      },
      "source": [
        "# loss before training\n",
        "model.forward(train_x[:32], train_y[:32])"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.3519)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ76bZPRwZcT"
      },
      "source": [
        "def train(epochs, bs, lr):\n",
        "    for e in range(epochs):\n",
        "        for bs_i in range((n-1)//bs + 1):\n",
        "            tot_w_mean, tot_w_std = 0, 0\n",
        "            str_idx, end_idx = bs_i*bs, (bs_i+1)*bs\n",
        "            x_batch, y_batch = train_x[str_idx:end_idx], train_y[str_idx:end_idx]\n",
        "            loss = model.forward(x_batch, y_batch)\n",
        "            model.backward()\n",
        "            \n",
        "            with no_grad():\n",
        "                for layer in model.layers:\n",
        "                    if hasattr(layer, 'w'): #if they have parameter attribute\n",
        "                        tot_w_mean+= layer.w.g.mean()\n",
        "                        tot_w_std += layer.w.g.std()\n",
        "                        layer.w -= layer.w.g * lr\n",
        "                        layer.b -= layer.b.g * lr\n",
        "                        layer.w.g.zero_() #initialize them to zero\n",
        "                        layer.b.g.zero_()\n",
        "            print(tot_w_mean/bs, tot_w_std/bs)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpPXcyAuyf5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93880b0c-3160-4b30-86d7-1225efb63917"
      },
      "source": [
        "train(1, 32, 1e-05)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.0630e-08) tensor(0.0846)\n",
            "tensor(1.8420e-08) tensor(0.0951)\n",
            "tensor(7.2576e-09) tensor(0.0817)\n",
            "tensor(9.8120e-08) tensor(0.1210)\n",
            "tensor(3.9064e-08) tensor(0.0846)\n",
            "tensor(4.2393e-08) tensor(0.0937)\n",
            "tensor(7.3088e-08) tensor(0.0970)\n",
            "tensor(3.0173e-08) tensor(0.0912)\n",
            "tensor(4.2076e-08) tensor(0.0880)\n",
            "tensor(4.6197e-08) tensor(0.0969)\n",
            "tensor(7.9697e-08) tensor(0.1115)\n",
            "tensor(1.5256e-08) tensor(0.0890)\n",
            "tensor(1.9776e-08) tensor(0.1191)\n",
            "tensor(1.4039e-08) tensor(0.0895)\n",
            "tensor(5.0751e-08) tensor(0.1062)\n",
            "tensor(1.9804e-08) tensor(0.1097)\n",
            "tensor(2.6974e-08) tensor(0.0940)\n",
            "tensor(1.6008e-08) tensor(0.0860)\n",
            "tensor(6.6563e-08) tensor(0.1098)\n",
            "tensor(2.7436e-08) tensor(0.0949)\n",
            "tensor(3.6265e-08) tensor(0.0952)\n",
            "tensor(1.7369e-08) tensor(0.0803)\n",
            "tensor(3.1584e-08) tensor(0.0572)\n",
            "tensor(6.4819e-08) tensor(0.1215)\n",
            "tensor(4.5498e-08) tensor(0.0871)\n",
            "tensor(1.4943e-08) tensor(0.1064)\n",
            "tensor(2.6058e-08) tensor(0.0876)\n",
            "tensor(1.8519e-08) tensor(0.0599)\n",
            "tensor(2.9099e-08) tensor(0.1045)\n",
            "tensor(2.1224e-08) tensor(0.0646)\n",
            "tensor(2.5717e-08) tensor(0.0871)\n",
            "tensor(8.0682e-09) tensor(0.0828)\n",
            "tensor(4.3233e-08) tensor(0.0933)\n",
            "tensor(1.8325e-08) tensor(0.0720)\n",
            "tensor(5.2287e-08) tensor(0.1047)\n",
            "tensor(8.0198e-08) tensor(0.0681)\n",
            "tensor(1.9964e-08) tensor(0.0934)\n",
            "tensor(4.3601e-08) tensor(0.1068)\n",
            "tensor(1.2073e-08) tensor(0.0979)\n",
            "tensor(3.4961e-08) tensor(0.1066)\n",
            "tensor(4.6483e-08) tensor(0.0898)\n",
            "tensor(9.4617e-09) tensor(0.0514)\n",
            "tensor(3.1111e-08) tensor(0.0896)\n",
            "tensor(1.1010e-08) tensor(0.0833)\n",
            "tensor(4.9650e-08) tensor(0.0993)\n",
            "tensor(6.2711e-08) tensor(0.0861)\n",
            "tensor(7.9577e-08) tensor(0.0921)\n",
            "tensor(3.9683e-08) tensor(0.0851)\n",
            "tensor(5.6070e-08) tensor(0.1098)\n",
            "tensor(1.2750e-08) tensor(0.0896)\n",
            "tensor(1.1405e-08) tensor(0.0685)\n",
            "tensor(1.7773e-08) tensor(0.0831)\n",
            "tensor(2.6405e-08) tensor(0.0943)\n",
            "tensor(3.3002e-10) tensor(0.0625)\n",
            "tensor(2.9711e-08) tensor(0.0996)\n",
            "tensor(6.9244e-08) tensor(0.0802)\n",
            "tensor(5.8396e-08) tensor(0.1020)\n",
            "tensor(2.9361e-08) tensor(0.0945)\n",
            "tensor(7.6271e-08) tensor(0.0911)\n",
            "tensor(2.2468e-08) tensor(0.0956)\n",
            "tensor(3.1146e-08) tensor(0.0798)\n",
            "tensor(4.2254e-08) tensor(0.1102)\n",
            "tensor(5.6529e-08) tensor(0.1029)\n",
            "tensor(2.1086e-08) tensor(0.0897)\n",
            "tensor(2.4284e-08) tensor(0.0806)\n",
            "tensor(1.4418e-08) tensor(0.0701)\n",
            "tensor(3.7792e-08) tensor(0.1101)\n",
            "tensor(4.4271e-08) tensor(0.0803)\n",
            "tensor(4.3633e-08) tensor(0.0844)\n",
            "tensor(4.8605e-08) tensor(0.0836)\n",
            "tensor(1.6290e-09) tensor(0.0851)\n",
            "tensor(2.6602e-08) tensor(0.0894)\n",
            "tensor(1.1371e-09) tensor(0.0925)\n",
            "tensor(3.0082e-08) tensor(0.0973)\n",
            "tensor(2.4990e-08) tensor(0.0850)\n",
            "tensor(-5.2161e-09) tensor(0.0546)\n",
            "tensor(2.0718e-08) tensor(0.0976)\n",
            "tensor(2.6844e-08) tensor(0.0697)\n",
            "tensor(1.5939e-08) tensor(0.0852)\n",
            "tensor(1.4105e-08) tensor(0.0970)\n",
            "tensor(1.9106e-08) tensor(0.1001)\n",
            "tensor(2.0079e-08) tensor(0.0852)\n",
            "tensor(1.1236e-08) tensor(0.0861)\n",
            "tensor(2.5423e-08) tensor(0.0904)\n",
            "tensor(6.1717e-08) tensor(0.0844)\n",
            "tensor(4.1354e-08) tensor(0.0684)\n",
            "tensor(5.4684e-08) tensor(0.0923)\n",
            "tensor(2.3573e-08) tensor(0.0696)\n",
            "tensor(1.3568e-08) tensor(0.0588)\n",
            "tensor(1.1193e-08) tensor(0.0404)\n",
            "tensor(3.3998e-08) tensor(0.1041)\n",
            "tensor(1.3113e-08) tensor(0.0683)\n",
            "tensor(-4.4656e-09) tensor(0.0964)\n",
            "tensor(-2.7294e-09) tensor(0.0761)\n",
            "tensor(-2.6257e-09) tensor(0.0726)\n",
            "tensor(2.6959e-08) tensor(0.0544)\n",
            "tensor(2.1666e-08) tensor(0.0575)\n",
            "tensor(2.1952e-08) tensor(0.0628)\n",
            "tensor(1.0219e-08) tensor(0.0469)\n",
            "tensor(2.2036e-08) tensor(0.0622)\n",
            "tensor(-5.5896e-09) tensor(0.0767)\n",
            "tensor(8.4652e-08) tensor(0.0952)\n",
            "tensor(3.5563e-08) tensor(0.0697)\n",
            "tensor(3.4369e-08) tensor(0.0812)\n",
            "tensor(1.4962e-08) tensor(0.0754)\n",
            "tensor(-4.7516e-09) tensor(0.0821)\n",
            "tensor(3.0637e-08) tensor(0.0896)\n",
            "tensor(5.6224e-08) tensor(0.0878)\n",
            "tensor(4.2070e-08) tensor(0.0849)\n",
            "tensor(5.0342e-08) tensor(0.1008)\n",
            "tensor(2.5773e-08) tensor(0.1043)\n",
            "tensor(4.2848e-08) tensor(0.1044)\n",
            "tensor(2.0626e-08) tensor(0.0548)\n",
            "tensor(4.6044e-08) tensor(0.1050)\n",
            "tensor(3.8302e-08) tensor(0.0604)\n",
            "tensor(4.1448e-08) tensor(0.1039)\n",
            "tensor(1.2165e-08) tensor(0.0722)\n",
            "tensor(2.8245e-08) tensor(0.0911)\n",
            "tensor(4.6129e-08) tensor(0.0777)\n",
            "tensor(4.2639e-08) tensor(0.0781)\n",
            "tensor(3.5452e-08) tensor(0.0832)\n",
            "tensor(6.7229e-08) tensor(0.0997)\n",
            "tensor(4.6331e-08) tensor(0.0855)\n",
            "tensor(5.0382e-08) tensor(0.0904)\n",
            "tensor(3.7772e-08) tensor(0.0908)\n",
            "tensor(1.3976e-08) tensor(0.0808)\n",
            "tensor(2.1560e-08) tensor(0.0825)\n",
            "tensor(4.0786e-08) tensor(0.0718)\n",
            "tensor(2.2485e-08) tensor(0.0578)\n",
            "tensor(-6.5057e-10) tensor(0.0819)\n",
            "tensor(-7.9297e-09) tensor(0.0596)\n",
            "tensor(3.3088e-08) tensor(0.0754)\n",
            "tensor(4.2228e-08) tensor(0.0863)\n",
            "tensor(2.1996e-08) tensor(0.0753)\n",
            "tensor(3.2172e-08) tensor(0.0579)\n",
            "tensor(4.8721e-08) tensor(0.0928)\n",
            "tensor(1.0138e-07) tensor(0.0949)\n",
            "tensor(6.1987e-08) tensor(0.0888)\n",
            "tensor(4.4979e-08) tensor(0.0697)\n",
            "tensor(3.2399e-08) tensor(0.0783)\n",
            "tensor(5.0424e-08) tensor(0.0932)\n",
            "tensor(6.3127e-08) tensor(0.0731)\n",
            "tensor(6.2614e-08) tensor(0.0856)\n",
            "tensor(3.3890e-08) tensor(0.0699)\n",
            "tensor(2.6865e-08) tensor(0.0881)\n",
            "tensor(9.8231e-09) tensor(0.0955)\n",
            "tensor(3.6503e-08) tensor(0.0892)\n",
            "tensor(3.8364e-09) tensor(0.0679)\n",
            "tensor(1.7441e-08) tensor(0.0905)\n",
            "tensor(4.9260e-08) tensor(0.0925)\n",
            "tensor(2.0403e-08) tensor(0.0832)\n",
            "tensor(1.2803e-08) tensor(0.0635)\n",
            "tensor(5.4875e-08) tensor(0.0555)\n",
            "tensor(2.6338e-08) tensor(0.0879)\n",
            "tensor(1.6972e-08) tensor(0.0841)\n",
            "tensor(1.2061e-08) tensor(0.0489)\n",
            "tensor(4.6551e-08) tensor(0.0610)\n",
            "tensor(7.9182e-08) tensor(0.0613)\n",
            "tensor(3.9289e-08) tensor(0.0742)\n",
            "tensor(5.6188e-08) tensor(0.0768)\n",
            "tensor(5.1720e-08) tensor(0.0896)\n",
            "tensor(1.6809e-08) tensor(0.0920)\n",
            "tensor(3.4881e-08) tensor(0.0787)\n",
            "tensor(1.8593e-08) tensor(0.0683)\n",
            "tensor(5.9540e-08) tensor(0.0763)\n",
            "tensor(2.9980e-08) tensor(0.0437)\n",
            "tensor(3.2345e-08) tensor(0.0688)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-psGH5eN6Vg0",
        "outputId": "473861ff-1cb1-4e21-ea23-bc91597ede4e"
      },
      "source": [
        "# loss after training\n",
        "model.forward(train_x[:32], train_y[:32])"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.8505)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGakSGQqDc4p"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye023wz2fv0Q",
        "outputId": "8120555d-5195-4898-dfc8-4a763a802b5a"
      },
      "source": [
        "model.forward(valid_x, valid_y)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.0253)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4awxiCLpgs0"
      },
      "source": [
        "pred = model.loss.yhat.max(-1).indices"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk6O6M2YDeE_"
      },
      "source": [
        "class Fscore():\n",
        "    def __init__(self, inp, trg):\n",
        "        self.inp, self.trg = inp, trg.max(-1).indices\n",
        "    def __call__(self, alpha = 0.5):\n",
        "        precision = self.precision()\n",
        "        recall = self.recall()\n",
        "        f1 = 2*precision*recall/(precision+recall)\n",
        "        return precision, recall, f1\n",
        "    \n",
        "    def precision(self):\n",
        "        tot_pre= 0.\n",
        "        for i in range(c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.inp ==i\n",
        "            if not sum(denom)==0: tot_pre += sum(numer) / sum(denom)\n",
        "        return tot_pre/c\n",
        "\n",
        "    def recall(self):\n",
        "        tot_rec= 0.\n",
        "        for i in range(c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.trg ==i\n",
        "            if not sum(denom)==0: tot_rec += sum(numer) / sum(denom)\n",
        "        return tot_rec/c"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJUJxDaasgRu",
        "outputId": "c856bdc0-257c-4f5c-d221-c792e38b29ca"
      },
      "source": [
        "measure = Fscore(pred, valid_y)\n",
        "measure()"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0213), tensor(1.0449), tensor(0.0417))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    }
  ]
}