{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-06-02-teamlab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "pBso0lVaEVFQ",
        "rWFjIv9tQmlC",
        "z_yD0VEfQruZ",
        "ytuvlMJiEse6",
        "wiOIVWcdFw-z",
        "1jc4jGdKFz_m",
        "Loh79wNZwS_o",
        "kkIo-zrIJach",
        "yJAe6BkZJXbu",
        "SrWlD4XhH7wT"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNOd8xN2U1a5YSRjdST3OCJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpellOnYou/CLab21/blob/arxiv/midterm/2021_06_02_teamlab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4mEW1YBEWAG"
      },
      "source": [
        "from pathlib import Path"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxJN-alkO9V"
      },
      "source": [
        "## Enviroment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k232czaeCGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2495444-4ee5-4609-86e1-ea8b0c6b40c4"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/CLab21.git'.format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: SpellOnYou\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0k0LvgOYDmV",
        "outputId": "dd05b414-9290-4ef2-bf80-570db9ba62da"
      },
      "source": [
        "%cd /content/CLab21"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CLab21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTZs6UIbYLiU",
        "outputId": "b272d8b1-28cd-4767-ea04-8f23633aeaa3"
      },
      "source": [
        "!git branch"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "* \u001b[32mmain\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HBwbAD7dYM9n",
        "outputId": "5759e50d-7d7a-440e-eb0b-b9c304be8682"
      },
      "source": [
        "# %cd /content/CLab21/exp/maxlen3000/\n",
        "# !cp -R /content/stats/maxlen3000/4layer .\n",
        "# !git log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CLab21/exp/maxlen3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RD9gi3CcYy7h"
      },
      "source": [
        "!git config --global user.name \"SpellOnYou\"\n",
        "!git config --global user.email \"jiwon.kim.096@gmail.com\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4I1R9zqYcxx"
      },
      "source": [
        "# !git add .\n",
        "# !git commit -m 'add maxlen3000 layer4 version'\n",
        "# !git push origin main"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uhrn4sxWEo15"
      },
      "source": [
        "src_path = Path('/content/CLab21/datasets/emotions/isear')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBso0lVaEVFQ"
      },
      "source": [
        "## Preprocess with sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7xryJ3gEYYY"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWFjIv9tQmlC"
      },
      "source": [
        "### text preprocessing (split x, y and remove noisy data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HthcqU6dKSAF"
      },
      "source": [
        "test_path = src_path/'isear-test-modified.csv'\n",
        "train_path = src_path/'isear-train-modified.csv'\n",
        "val_path = src_path/'isear-val-modified.csv'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyFImnWtEpHI"
      },
      "source": [
        "!cut -f2- -d ',' {str(train_path)} > 'isear-train-modified-text'\n",
        "!cut -f2- -d ',' {str(val_path)} > 'isear-val-modified-text'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7tOa22APtS4"
      },
      "source": [
        "!cut -f1 -d ',' {str(train_path)} > 'isear-train-modified-label'\n",
        "!cut -f1 -d ',' {str(val_path)} > 'isear-val-modified-label'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXpbw7nUM2TY"
      },
      "source": [
        "with open('isear-val-modified-text') as f:\n",
        "    lines= f.readlines()\n",
        "# remove header\n",
        "val_text = lines[1:]\n",
        "\n",
        "\n",
        "with open('isear-train-modified-text') as f:\n",
        "    lines= f.readlines()\n",
        "# remove header\n",
        "train_text = lines[1:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa2lw7QH-l8x",
        "outputId": "11e2359d-87e0-42e4-ea17-b3fc96e77fb5"
      },
      "source": [
        "len(train_text), len(val_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4939, 1107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnkyYdegOpwX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f959f89b-a2b1-4b46-d3fe-0dfc7b25a5b3"
      },
      "source": [
        "f\"number of train doc: {len(train_text)} / num of val doc: {len(val_text)}\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'number of train doc: 4939 / num of val doc: 1107'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KUl_05MEppM"
      },
      "source": [
        "tfidf = TfidfVectorizer(stop_words='english')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U1de6uzEp-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f377f3d-36f5-422a-fb3b-08912bffd18c"
      },
      "source": [
        "tfidf.fit_transform(train_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4939x7018 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 41742 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYUOnk_qOdyV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "296c8d79-5ef3-403e-98f4-588d0714563c"
      },
      "source": [
        "tfidf.fit_transform(val_text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<1107x3028 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 9304 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AtH_JRW0_AXx"
      },
      "source": [
        "from torch import tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luT4ygxbEqEH"
      },
      "source": [
        "# slide by 3000 features as default version did.\n",
        "x_train = tfidf.fit_transform(train_text)[:, :3000]\n",
        "x_valid = tfidf.fit_transform(val_text)[:, :3000]\n",
        "\n",
        "# dir(x_valid), \n",
        "# type(x_valid.todense())\n",
        "\n",
        "x_train, x_valid = map(tensor, (x_train.todense(), x_valid.todense()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_yD0VEfQruZ"
      },
      "source": [
        "### one-hot encoded data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WpR3g0LS8SV"
      },
      "source": [
        "from torch import zeros"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmSHpKNAQtQ2"
      },
      "source": [
        "class OneHotEncode():\n",
        "    def __init__(self):\n",
        "        self.label2idx = {}\n",
        "        self.idx2label = {}\n",
        "    def __call__(self, f_name, is_train=True):\n",
        "        with open(f_name) as f:\n",
        "            labels = f.read().lower().split('\\n')[1:-1]\n",
        "        \n",
        "        if is_train:\n",
        "            self.label2idx = {label: idx for idx, label in enumerate(set(labels)) if label}\n",
        "            self.idx2label = {v:k for k, v in self.label2idx.items()}\n",
        "        # convert to numeric variable\n",
        "        labels = [self.label2idx[label] for label in labels]\n",
        "        # make one-hot vector\n",
        "        one_hot_vector = zeros(len(labels), len(set(labels)))\n",
        "        one_hot_vector[range(one_hot_vector.shape[0]), labels] = 1\n",
        "        return one_hot_vector\n",
        "\n",
        "y_encode = OneHotEncode()\n",
        "y_train= y_encode('isear-train-modified-label')\n",
        "y_valid= y_encode('isear-val-modified-label', is_train=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SIOxVBOWL_7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytuvlMJiEse6"
      },
      "source": [
        "## Preprocess with Lara's code\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wiOIVWcdFw-z"
      },
      "source": [
        "### y label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_p_RAdlF8WM"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "class OneHotEncoding:\n",
        "    def __init__(self, file_name):\n",
        "        self.mapping_dict = {}\n",
        "        #self.csv_file = pd.read_csv(file_name)\n",
        "        #self.labels = self.csv_file[\"label\"]\n",
        "\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.labels = []\n",
        "        for col in self.csv_file:\n",
        "            self.labels.append(col[\"label\"])\n",
        "\n",
        "        self.target_labels = []\n",
        "        for word in self.labels:\n",
        "            if word not in self.target_labels:\n",
        "                self.target_labels.append(word)\n",
        "\n",
        "        #self.target_labels = self.labels.unique()\n",
        "        self.labels_dict = {}\n",
        "        self.mapping()\n",
        "\n",
        "    def get_unique_labels(self):\n",
        "\n",
        "        return self.target_labels\n",
        "\n",
        "    def mapping(self):\n",
        "        ### map each emotion to an integer\n",
        "        one_hot_encoded = []\n",
        "        for label_idx in range(len(self.target_labels)):\n",
        "            self.mapping_dict[self.target_labels[label_idx]] = label_idx\n",
        "        #print(self.mapping_dict)\n",
        "\n",
        "        for c in self.target_labels:\n",
        "            arr = list(np.zeros(len(self.target_labels), dtype=int))\n",
        "            arr[self.mapping_dict[c]] = 1\n",
        "            one_hot_encoded.append(arr)\n",
        "\n",
        "        self.generate_dictionary(one_hot_encoded)\n",
        "\n",
        "        return one_hot_encoded\n",
        "\n",
        "    def generate_dictionary(self, one_hot_encoded):\n",
        "        self.labels_dict = dict(zip(self.target_labels, one_hot_encoded))  # universal dict\n",
        "\n",
        "    def one_hot_encoding(self, encoded_dict=None):\n",
        "        df_labels = []\n",
        "        if encoded_dict is None:\n",
        "            encoded_dict = self.labels_dict\n",
        "        for c in self.labels:\n",
        "            if c in encoded_dict.keys():\n",
        "                df_labels.append(encoded_dict[c])\n",
        "        return np.array(df_labels)\n",
        "\n",
        "    def get_encoded_dict(self):\n",
        "        return self.labels_dict\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jc4jGdKFz_m"
      },
      "source": [
        "### x label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMVS77h1Ewoh"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "\n",
        "class PadMaxLength:\n",
        "\n",
        "    def __init__(self, file_name):\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.list_padded_sentences = []\n",
        "        self.text = []\n",
        "        for col in self.csv_file:\n",
        "            self.text.append(col[\"text\"])\n",
        "\n",
        "    def min_max_sentences(self):\n",
        "        tokenized_sentences = []\n",
        "        # split each sentence into words\n",
        "        for sentence in self.text:\n",
        "            tokens = sentence.split()\n",
        "            tokenized_sentences.append(tokens)\n",
        "        # get longest sentence and its length\n",
        "        longest_sent = max(tokenized_sentences, key=len)\n",
        "        longest_sent_len = len(longest_sent)\n",
        "\n",
        "        # get shortest word and its length\n",
        "        shortest_sent = min(tokenized_sentences, key=len)\n",
        "        shortest_sent_len = len(shortest_sent)\n",
        "\n",
        "        return longest_sent_len, shortest_sent_len\n",
        "\n",
        "    def right_pad_sentences(self, max_sent_length):\n",
        "        max_len = round(max_sent_length * 0.50)  # Take 50% of the maximum sentence length to avoid sparsity\n",
        "        padded_sentences = []\n",
        "        # print(max_len)\n",
        "\n",
        "        for sentence in self.text:\n",
        "            sentence = sentence.strip()\n",
        "            sentence = sentence.split()\n",
        "\n",
        "            if len(sentence) > max_len:\n",
        "                a = sentence[:max_len]  # discard tokens longer than max_length\n",
        "                padded_sentences.append(a)\n",
        "\n",
        "            elif len(sentence) < max_len:\n",
        "                [sentence.append(\"0\") for i in\n",
        "                 range(max_len - len(sentence))]  # pad sentences with zeros smaller than max_length\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "            else:\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "        for pad_sent in padded_sentences:\n",
        "            list_sentences = ' '.join(pad_sent)\n",
        "            self.list_padded_sentences.append(list_sentences)\n",
        "\n",
        "        return self.list_padded_sentences\n",
        "\n",
        "    def merge_with(self, list2, list3):\n",
        "        merged = self.list_padded_sentences + list2 + list3\n",
        "        return merged\n",
        "\n",
        "class BagOfWords:\n",
        "\n",
        "    def __init__(self, list_of_sentences):\n",
        "\n",
        "        # define punctuation and upper case alphabet\n",
        "        self.punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "        self.upper = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "        self.stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\n",
        "                          \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself',\n",
        "                          'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
        "                          'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",\n",
        "                          'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has',\n",
        "                          'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
        "                          'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',\n",
        "                          'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',\n",
        "                          'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once',\n",
        "                          'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
        "                          'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than',\n",
        "                          'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now',\n",
        "                          'd',\n",
        "                          'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn',\n",
        "                          \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\",\n",
        "                          'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
        "                          'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won',\n",
        "                          \"won't\", 'wouldn', \"wouldn't\"]\n",
        "        self.vocab = self.generate_vocabulary(list_of_sentences)  # Generate the vocabulary\n",
        "        # print(len(self.vocab))\n",
        "        self.dict_idx = self.indexing(self.vocab)  # Generate the indexing\n",
        "        self.word_count = self.count_dictionary(list_of_sentences)\n",
        "        self.N_sentences = len(list_of_sentences)\n",
        "        self.idf_train = {}\n",
        "\n",
        "    def lowercase_tokenize(self, padded_sentences):\n",
        "        lowercase = \"\"\n",
        "        for char in padded_sentences:\n",
        "            if char in self.upper:\n",
        "                k = ord(char)\n",
        "                l = k + 32\n",
        "                lowercase = lowercase + (chr(l))\n",
        "            elif char in self.punctuations:\n",
        "                continue\n",
        "            else:\n",
        "                lowercase = lowercase + char\n",
        "        lowercase = lowercase.strip()\n",
        "        tokenized = list(lowercase.split())\n",
        "        return tokenized\n",
        "\n",
        "    def remove_stopwords(self, tokenized_sentences):\n",
        "        filtered_list = []\n",
        "        for token in tokenized_sentences:\n",
        "            if token in self.stopwords:\n",
        "                continue\n",
        "            else:\n",
        "                filtered_list.append(token)\n",
        "        return filtered_list\n",
        "\n",
        "    def generate_vocabulary(self, all_padded_sentences):\n",
        "        vocab = []\n",
        "        for sentence in all_padded_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            filtered_tokenized_sentence = self.remove_stopwords(tokenized_sentence)\n",
        "            for word in filtered_tokenized_sentence:  # append only unique words\n",
        "                if word not in vocab:\n",
        "                    vocab.append(word)\n",
        "        return vocab\n",
        "\n",
        "    def indexing(self, tokens):\n",
        "        # Index dictionary to assign an index to each word in vocabulary\n",
        "        index_word = {}\n",
        "        i = 0\n",
        "        for word in tokens:\n",
        "            index_word[word] = i\n",
        "            i += 1\n",
        "        return index_word\n",
        "\n",
        "    def count_dictionary(self, input_sentences):\n",
        "        word_count = {}\n",
        "        for word in self.vocab:\n",
        "            word_count[word] = 0.0\n",
        "            for sentence in input_sentences:\n",
        "                if word in sentence:\n",
        "                    word_count[word] += 1.0\n",
        "        return word_count\n",
        "\n",
        "    # Term Frequency\n",
        "    def termfreq(self, sentence, word):\n",
        "        sentence_length = float(len(sentence))\n",
        "        occurrence = float(len([token for token in sentence if token == word]))\n",
        "        return occurrence / sentence_length\n",
        "\n",
        "    def inverse_doc_freq(self, word):\n",
        "        try:\n",
        "            word_occurrence = self.word_count[word] + 1.0\n",
        "        except KeyError:\n",
        "            word_occurrence = 1.0\n",
        "        return np.log(self.N_sentences / word_occurrence)\n",
        "\n",
        "    def tf_idf(self, input_sentences, train=True):\n",
        "        row = 0\n",
        "        tf_idf_vec = np.zeros(((len(input_sentences)), (len(self.vocab))))\n",
        "\n",
        "        for sentence in input_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            filtered_tokenized_sentence = self.remove_stopwords(tokenized_sentence)\n",
        "            for word in filtered_tokenized_sentence:\n",
        "                tf = self.termfreq(filtered_tokenized_sentence, word)\n",
        "                if train:\n",
        "                    idf = self.inverse_doc_freq(word)\n",
        "                    self.idf_train[word] = idf\n",
        "                    value = tf * idf\n",
        "                else:\n",
        "                    try:\n",
        "                        value = tf * self.idf_train[word]\n",
        "                    except KeyError:\n",
        "                        continue\n",
        "\n",
        "                tf_idf_vec[row][self.dict_idx[word]] = value\n",
        "\n",
        "            row += 1\n",
        "\n",
        "        return tf_idf_vec"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loh79wNZwS_o"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ckMvLZvF2Q"
      },
      "source": [
        "class Linear():\n",
        "    def __init__(self, w, b):\n",
        "        self.w, self.b = w, b\n",
        "    def forward(self, x): \n",
        "        self.inp = x\n",
        "        self.out = self.inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        # set_trace()\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)\n",
        "\n",
        "\n",
        "class Relu():\n",
        "    def forward(self, x):\n",
        "        self.inp = x\n",
        "        self.out = x.clamp_min(0.) - 0.5\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g* (self.inp>0).float()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H584_Yc07IL6"
      },
      "source": [
        "class CrossEntropy():\n",
        "    def __call__(self, pred, y):\n",
        "        \n",
        "        self.yhat, self.y = pred, y\n",
        "        #P(\\hat{y})\n",
        "        self.log_p_yhat = self.log_softmax(pred)\n",
        "        self.out = self.nll(self.log_p_yhat, y)\n",
        "        \n",
        "        return self.out\n",
        "\n",
        "    #negative log likelihood\n",
        "    def nll(self, pred, y):\n",
        "        # print(pred.shape, y.shape)\n",
        "        return -pred[range(y.shape[0]), y.max(-1).indices].mean()\n",
        "\n",
        "    def log_softmax(self, x): return x - x.exp().sum(-1,keepdim=True).log()\n",
        "\n",
        "    def backward(self):\n",
        "        softmax = 1/ (1+(-self.yhat).exp())\n",
        "        # set_trace()\n",
        "        self.yhat.g = (softmax - self.y)\n",
        "\n",
        "class DummyModel():\n",
        "    def __init__(self, n_layers, *args):\n",
        "        self.loss = CrossEntropy()\n",
        "        self.args = args\n",
        "        self.layers = []\n",
        "        for i in range(0, n_layers-1):\n",
        "            self.layers += [Linear(args[i*2], args[(i*2)+1]), Relu()]\n",
        "        self.layers += [Linear(args[-2], args[-1])]\n",
        "    \n",
        "    def forward(self, x):\n",
        "        self.x= x\n",
        "        for layer in self.layers:\n",
        "            x = layer.forward(x)\n",
        "        self.out = x\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for layer in reversed(self.layers):\n",
        "            layer.backward()\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq2HSyanCKra"
      },
      "source": [
        "class Fscore():\n",
        "    def __init__(self, inp, trg):\n",
        "        self.inp, self.trg = inp.max(-1).indices, trg.max(-1).indices\n",
        "        self.c = inp.shape[1]\n",
        "    def __call__(self, alpha = 0.5):\n",
        "        self.precision()\n",
        "        self.recall()\n",
        "        f1 = map(\n",
        "            self.fscore, self.tot_pre, self.tot_rec\n",
        "            )\n",
        "        return self.tot_pre, self.tot_rec, list(f1)\n",
        "    def fscore(self, x, y):\n",
        "        return (2*x*y)/(x+y)\n",
        "    \n",
        "    def precision(self):\n",
        "        self.tot_pre= []\n",
        "        for i in range(self.c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.inp ==i\n",
        "            if not sum(denom)==0: self.tot_pre += [sum(numer) / sum(denom)]\n",
        "            else: self.tot_pre += [0.]\n",
        "\n",
        "    def recall(self):\n",
        "        self.tot_rec= []\n",
        "        for i in range(self.c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.trg ==i\n",
        "            if not sum(denom)==0: self.tot_rec += [sum(numer) / sum(denom)]\n",
        "            else: self.tot_rec += [0.]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4aEwhi9BjoL"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EWlD51R_68gY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f24683d1-d8db-4456-da5c-2b43ead22284"
      },
      "source": [
        "# # in case you need debug\n",
        "!pip install -q ipdb\n",
        "from ipdb import set_trace"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 788kB 3.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 368kB 7.2MB/s \n",
            "\u001b[?25h  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: jupyter-console 5.2.0 has requirement prompt-toolkit<2.0.0,>=1.0.0, but you'll have prompt-toolkit 3.0.18 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement ipython~=5.5.0, but you'll have ipython 7.24.1 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-jCQoJpMOeg"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_rqwvxHDDfO"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqfMvzIJ--Qz"
      },
      "source": [
        "import numpy as np\n",
        "import csv, math\n",
        "from torch import tensor, float32, randn, no_grad"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDyIM1IQFAii"
      },
      "source": [
        "test_path = src_path/'isear-test-modified.csv'\n",
        "train_path = src_path/'isear-train-modified.csv'\n",
        "val_path = src_path/'isear-val-modified.csv'\n",
        "\n",
        "pml_train = PadMaxLength(train_path)\n",
        "pml_val = PadMaxLength(val_path)\n",
        "pml_test = PadMaxLength(test_path)\n",
        "\n",
        "bow_train = BagOfWords(pml_train.text)  # Sentences to create the vocabulary\n",
        "\n",
        "tf_idf_train = bow_train.tf_idf(pml_train.text)\n",
        "tf_idf_val = bow_train.tf_idf(pml_val.text, train=False)\n",
        "tf_idf_test = bow_train.tf_idf(pml_test.text, train=False)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CRVoTIqGDzz"
      },
      "source": [
        "ohe_train = OneHotEncoding(train_path)\n",
        "ohe_val = OneHotEncoding(val_path)\n",
        "ohe_test = OneHotEncoding(test_path)\n",
        "reference_dict = ohe_train.get_encoded_dict()\n",
        "y_train = ohe_train.one_hot_encoding()\n",
        "y_val = ohe_val.one_hot_encoding(reference_dict)\n",
        "y_test = ohe_test.one_hot_encoding(reference_dict)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vg-XuYKAKTkh"
      },
      "source": [
        "## Data type is not matched.......\n",
        "\n",
        "can you use numpy float32 instead of 64?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZEQJzYLJnGM",
        "outputId": "00765305-be9f-4e0a-94d8-509c0255ecb6"
      },
      "source": [
        "tf_idf_train.dtype, tf_idf_val.dtype, tf_idf_test.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(dtype('float64'), dtype('float64'), dtype('float64'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHK9YwztJySs",
        "outputId": "c90d7053-b843-4a3b-e66f-da37f46413a9"
      },
      "source": [
        "y_train.dtype, y_val.dtype"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.int64, dtype('int64'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhW_uBqaSPqt",
        "outputId": "baf9ff25-fa41-4996-9a5f-0b1f9c22e33a"
      },
      "source": [
        "tf_idf_test.shape, y_test.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1121, 7449), (1121, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRwKN6JhCdEh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KEd6fHMhG2gr"
      },
      "source": [
        "def init_dataset(max_len, is_test = False):\n",
        "\n",
        "    #Lara's version\n",
        "    \n",
        "    tf_idf_train = bow_train.tf_idf(pml_train.text)[:, :max_len]\n",
        "    tf_idf_val = bow_train.tf_idf(pml_val.text, train=False)[:, :max_len]\n",
        "    tf_idf_test = bow_train.tf_idf(pml_test.text, train=False)[:, :max_len]\n",
        "    \n",
        "    tf_idf_train, tf_idf_val, tf_idf_test = map(np.float32, (tf_idf_train, tf_idf_val, tf_idf_test))\n",
        "    \n",
        "    y_train = ohe_train.one_hot_encoding()\n",
        "    y_val = ohe_val.one_hot_encoding(reference_dict)\n",
        "    y_test = ohe_test.one_hot_encoding(reference_dict)\n",
        "\n",
        "    if is_test: return map(tensor, (tf_idf_train, y_train, tf_idf_test, y_test))\n",
        "    return map(tensor, (tf_idf_train, y_train, tf_idf_val, y_val))\n",
        "\n",
        "    #scikit-learn version\n",
        "    \n",
        "    # x_train = tfidf.fit_transform(train_text)[:, :max_len]\n",
        "    # x_valid = tfidf.fit_transform(val_text)[:, :max_len]\n",
        "    # x_train, x_valid = map(tensor, (x_train.todense(), x_valid.todense()))\n",
        "    # y_train= y_encode('isear-train-modified-label')\n",
        "    # y_valid= y_encode('isear-val-modified-label', is_train=False)\n",
        "    # return x_train.float(), y_train, x_valid.float(), y_valid"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IryV26tHYJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af768507-64b6-4cac-b822-f22c375c560d"
      },
      "source": [
        "x_train, y_train, x_valid, y_valid = init_dataset(3000)\n",
        "x_train.shape, y_train.shape, x_valid.shape, y_valid.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4933, 3000]),\n",
              " torch.Size([4933, 7]),\n",
              " torch.Size([1107, 3000]),\n",
              " torch.Size([1107, 7]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5coTmr8DHgsY",
        "outputId": "526bb710-81b5-4d44-b1e7-f2156f490ed6"
      },
      "source": [
        "x_train, y_train, x_test, y_test = init_dataset(3000, 1)\n",
        "x_train.shape, y_train.shape, x_test.shape, y_test.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([4933, 3000]),\n",
              " torch.Size([4933, 7]),\n",
              " torch.Size([1121, 3000]),\n",
              " torch.Size([1121, 7]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZBx1tYwcke"
      },
      "source": [
        "#n: data size m: n_text_feature h: hidden node c: out node\n",
        "n, m, h, c = *x_train.shape, 100, y_train.shape[1]"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7qPK6zc86Hm"
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ76bZPRwZcT"
      },
      "source": [
        "class Runner():\n",
        "    '''\n",
        "    train & validate (note: no use of test set)\n",
        "    this class gets train, valid, model and experiment with various hyperparameters including layer depth\n",
        "    '''\n",
        "\n",
        "    def __init__(self, train, valid, model):\n",
        "        '''\n",
        "        Args:\n",
        "            train(tuple): (x_train, y_train)\n",
        "            valid(tuple): (x_valid, y_valid)\n",
        "            model from DummyModel\n",
        "        '''\n",
        "        self.x_train, self.y_train = train\n",
        "        self.x_valid, self.y_valid = valid\n",
        "        self.model = model\n",
        "        # cumulative statistics of each batch (mean, std)\n",
        "        self.cum_batch = defaultdict(list)\n",
        "\n",
        "    def train(self, epochs, bs, lr):\n",
        "\n",
        "        #to record\n",
        "        self.epochs, self.bs, self.lr = epochs, bs, lr\n",
        "        '''\n",
        "        Args:\n",
        "                                                                                                       \n",
        "        '''\n",
        "\n",
        "        for e in range(epochs):\n",
        "            for bs_i in range((n-1)//bs + 1):\n",
        "                # tot_w_mean, tot_w_std = 0, 0\n",
        "                str_idx, end_idx = bs_i*bs, (bs_i+1)*bs\n",
        "                x_batch, y_batch = self.x_train[str_idx:end_idx], self.y_train[str_idx:end_idx]\n",
        "                prediction = self.model.forward(x_batch)\n",
        "                loss = self.model.loss(prediction, y_batch)\n",
        "\n",
        "                self.model.backward()\n",
        "                \n",
        "                with no_grad():\n",
        "                    for l_i, layer in enumerate(self.model.layers):\n",
        "                        if hasattr(layer, 'w'): #if they have parameter attribute\n",
        "                            self.cum_batch[l_i].append([layer.w.g.mean(), layer.w.g.std()])\n",
        "                            layer.w -= layer.w.g * lr\n",
        "                            layer.b -= layer.b.g * lr\n",
        "                            layer.w.g.zero_() #initialize them to zero\n",
        "                            layer.b.g.zero_()\n",
        "                # if bs_i % 100 ==0: print(tot_w_mean/bs, tot_w_std/bs)\n",
        "    def evaluate(self):\n",
        "        pred_valid = self.model.forward(self.x_valid)\n",
        "        loss_valid = self.model.loss(pred_valid, self.y_valid)\n",
        "        softmax_pred = self.model.loss.log_softmax(pred_valid)\n",
        "        measure = Fscore(softmax_pred, self.y_valid)\n",
        "        p, r, f = measure()\n",
        "        # trg_names = list(y_encode.label2idx.keys())\n",
        "        trg_names = list(reference_dict.keys())\n",
        "        df = pd.DataFrame(classification_report(y_true = self.y_valid.max(-1).indices, y_pred = softmax_pred.max(-1).indices, target_names=trg_names, output_dict=1))\n",
        "        \n",
        "        return df.transpose(), self.cum_batch"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fApnIINUs6eU"
      },
      "source": [
        " ```3000, layer == 2, batch size 16 and at least 5 epochs```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLF_gr5fIhcg"
      },
      "source": [
        "#Hyper parameter tuning with validation data, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZoBAKQMIDlO"
      },
      "source": [
        "lrs = np.linspace(1e-1, 1e-10, 9)\n",
        "epochs = range(1, 15, 2)\n",
        "batches = [16,32,64]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1b1jGW1BoP8"
      },
      "source": [
        "import pickle"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTj3zRRISHPj"
      },
      "source": [
        "from time import time"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eT1h0t6cH1lR"
      },
      "source": [
        "# when max length = 3000\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFD5H_5EAKLn"
      },
      "source": [
        "max1_path = Path('/content/stats/maxlen3000'); max1_path.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w27YD0DGu3D"
      },
      "source": [
        "## when layer == 2 (3000 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB-mgo1NGu3E"
      },
      "source": [
        "path2 = max1_path/'2layer'; path2.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path2/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path2/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BzFFjP0Gu3E"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPP1-NirxJfo"
      },
      "source": [
        "x_train, y_train, x_test, y_test = init_dataset(3000, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzfGyFN5xMTN",
        "outputId": "f6d9f70f-0ced-48fc-e546-157d3282e852"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1107, 3000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "havOofg9xO3J",
        "outputId": "d2e478e6-866c-4f20-ace5-91f424bc05ea"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1121, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "301993RvGu3E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff02f9b-5f85-47e5-8c3f-b267fcaf7c77"
      },
      "source": [
        "def layer_2_param_init():\n",
        "    w1 = randn(3000, 100) / math.sqrt(100)\n",
        "    w2 = randn(100, 7) / math.sqrt(7)\n",
        "\n",
        "    b1 = randn(100)\n",
        "    b2 = randn(7)\n",
        "\n",
        "    return w1, b1, w2, b2\n",
        "\n",
        "def layer_2(epochs, lrs, batches):\n",
        "    ranks = []\n",
        "    for epoch in epochs:\n",
        "        start_epoch = time()\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                start_bs = time()\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset(3000, 0)\n",
        "                w1, b1, w2, b2 = layer_2_param_init()\n",
        "                model = DummyModel(2,w1, b1, w2, b2)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))\n",
        "                print(f\"epoch: {epoch}, lr: {lr}, bs: {bs}\")                \n",
        "                \n",
        "                print(f\"took {time()-start_bs} seconds for a one batch\")\n",
        "        print(f'{time() - start_epoch}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 4, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.624664545059204 seconds for a one batch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 4, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.083317041397095 seconds for a one batch\n",
            "epoch: 4, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.715315341949463 seconds for a one batch\n",
            "epoch: 4, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.81389331817627 seconds for a one batch\n",
            "epoch: 4, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.066752672195435 seconds for a one batch\n",
            "epoch: 4, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.672718524932861 seconds for a one batch\n",
            "epoch: 4, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.89757490158081 seconds for a one batch\n",
            "epoch: 4, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.042316436767578 seconds for a one batch\n",
            "epoch: 4, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.680246829986572 seconds for a one batch\n",
            "epoch: 4, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.877671003341675 seconds for a one batch\n",
            "epoch: 4, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.220079898834229 seconds for a one batch\n",
            "epoch: 4, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.813459873199463 seconds for a one batch\n",
            "epoch: 4, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.22890329360962 seconds for a one batch\n",
            "epoch: 4, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.118619680404663 seconds for a one batch\n",
            "epoch: 4, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.765986204147339 seconds for a one batch\n",
            "epoch: 4, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.068085432052612 seconds for a one batch\n",
            "epoch: 4, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.554847240447998 seconds for a one batch\n",
            "epoch: 4, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.660460472106934 seconds for a one batch\n",
            "epoch: 4, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.487676858901978 seconds for a one batch\n",
            "epoch: 4, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.489048957824707 seconds for a one batch\n",
            "epoch: 4, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.81112790107727 seconds for a one batch\n",
            "epoch: 4, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.609816789627075 seconds for a one batch\n",
            "epoch: 4, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.507376432418823 seconds for a one batch\n",
            "epoch: 4, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.719525575637817 seconds for a one batch\n",
            "epoch: 4, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.679666996002197 seconds for a one batch\n",
            "epoch: 4, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.483131885528564 seconds for a one batch\n",
            "epoch: 4, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.709038496017456 seconds for a one batch\n",
            "246.4040801525116\n",
            "epoch: 5, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.744879722595215 seconds for a one batch\n",
            "epoch: 5, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.37260890007019 seconds for a one batch\n",
            "epoch: 5, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.583678245544434 seconds for a one batch\n",
            "epoch: 5, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.779464960098267 seconds for a one batch\n",
            "epoch: 5, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.278944969177246 seconds for a one batch\n",
            "epoch: 5, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.56594204902649 seconds for a one batch\n",
            "epoch: 5, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.857802152633667 seconds for a one batch\n",
            "epoch: 5, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.344923496246338 seconds for a one batch\n",
            "epoch: 5, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.579434394836426 seconds for a one batch\n",
            "epoch: 5, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.68823528289795 seconds for a one batch\n",
            "epoch: 5, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.390719890594482 seconds for a one batch\n",
            "epoch: 5, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.557793140411377 seconds for a one batch\n",
            "epoch: 5, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.777517080307007 seconds for a one batch\n",
            "epoch: 5, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.46161675453186 seconds for a one batch\n",
            "epoch: 5, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.630411863327026 seconds for a one batch\n",
            "epoch: 5, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.818798303604126 seconds for a one batch\n",
            "epoch: 5, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.446385145187378 seconds for a one batch\n",
            "epoch: 5, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.706809759140015 seconds for a one batch\n",
            "epoch: 5, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.592619895935059 seconds for a one batch\n",
            "epoch: 5, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.214756727218628 seconds for a one batch\n",
            "epoch: 5, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.41356348991394 seconds for a one batch\n",
            "epoch: 5, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.639611959457397 seconds for a one batch\n",
            "epoch: 5, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.399901390075684 seconds for a one batch\n",
            "epoch: 5, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.357799530029297 seconds for a one batch\n",
            "epoch: 5, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 11.288043022155762 seconds for a one batch\n",
            "epoch: 5, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.126201391220093 seconds for a one batch\n",
            "epoch: 5, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 10.485939502716064 seconds for a one batch\n",
            "293.1081943511963\n",
            "epoch: 6, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 15.406967401504517 seconds for a one batch\n",
            "epoch: 6, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 13.676234245300293 seconds for a one batch\n",
            "epoch: 6, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.39560055732727 seconds for a one batch\n",
            "epoch: 6, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.565315246582031 seconds for a one batch\n",
            "epoch: 6, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.96070909500122 seconds for a one batch\n",
            "epoch: 6, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.214565992355347 seconds for a one batch\n",
            "epoch: 6, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.553297281265259 seconds for a one batch\n",
            "epoch: 6, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.933480978012085 seconds for a one batch\n",
            "epoch: 6, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.185529708862305 seconds for a one batch\n",
            "epoch: 6, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.77080225944519 seconds for a one batch\n",
            "epoch: 6, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.900241613388062 seconds for a one batch\n",
            "epoch: 6, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.140156984329224 seconds for a one batch\n",
            "epoch: 6, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.655521869659424 seconds for a one batch\n",
            "epoch: 6, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.90544843673706 seconds for a one batch\n",
            "epoch: 6, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.174773693084717 seconds for a one batch\n",
            "epoch: 6, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 12.190505266189575 seconds for a one batch\n",
            "epoch: 6, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.33937382698059 seconds for a one batch\n",
            "epoch: 6, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.212482213973999 seconds for a one batch\n",
            "epoch: 6, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 12.041564464569092 seconds for a one batch\n",
            "epoch: 6, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.400458574295044 seconds for a one batch\n",
            "epoch: 6, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.26285457611084 seconds for a one batch\n",
            "epoch: 6, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 12.01914095878601 seconds for a one batch\n",
            "epoch: 6, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.522195100784302 seconds for a one batch\n",
            "epoch: 6, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.194079875946045 seconds for a one batch\n",
            "epoch: 6, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 12.108594417572021 seconds for a one batch\n",
            "epoch: 6, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 10.461923837661743 seconds for a one batch\n",
            "epoch: 6, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 12.109885931015015 seconds for a one batch\n",
            "331.3059871196747\n",
            "epoch: 7, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.725372791290283 seconds for a one batch\n",
            "epoch: 7, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.891183853149414 seconds for a one batch\n",
            "epoch: 7, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 13.996707201004028 seconds for a one batch\n",
            "epoch: 7, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.869592189788818 seconds for a one batch\n",
            "epoch: 7, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.971561908721924 seconds for a one batch\n",
            "epoch: 7, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 14.017918825149536 seconds for a one batch\n",
            "epoch: 7, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.924749612808228 seconds for a one batch\n",
            "epoch: 7, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 12.053322076797485 seconds for a one batch\n",
            "epoch: 7, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 14.013612747192383 seconds for a one batch\n",
            "epoch: 7, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.88279414176941 seconds for a one batch\n",
            "epoch: 7, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.92861819267273 seconds for a one batch\n",
            "epoch: 7, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 13.9907546043396 seconds for a one batch\n",
            "epoch: 7, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.84342622756958 seconds for a one batch\n",
            "epoch: 7, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.603614568710327 seconds for a one batch\n",
            "epoch: 7, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 14.017112731933594 seconds for a one batch\n",
            "epoch: 7, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.579837560653687 seconds for a one batch\n",
            "epoch: 7, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.054598569869995 seconds for a one batch\n",
            "epoch: 7, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 13.99471640586853 seconds for a one batch\n",
            "epoch: 7, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.38179326057434 seconds for a one batch\n",
            "epoch: 7, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.030775785446167 seconds for a one batch\n",
            "epoch: 7, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 14.107335805892944 seconds for a one batch\n",
            "epoch: 7, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.604910135269165 seconds for a one batch\n",
            "epoch: 7, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.107602834701538 seconds for a one batch\n",
            "epoch: 7, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 14.06748080253601 seconds for a one batch\n",
            "epoch: 7, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 13.6446053981781 seconds for a one batch\n",
            "epoch: 7, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 11.07110047340393 seconds for a one batch\n",
            "epoch: 7, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 14.001634120941162 seconds for a one batch\n",
            "353.3795630931854\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZL-aOxVWTXZ7"
      },
      "source": [
        "layer_2(epochs = epochs, lrs = lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkIo-zrIJach"
      },
      "source": [
        "## when layer == 6 (3000 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZaYImrfABuJv"
      },
      "source": [
        "path6 = max1_path/'6layer'; path6.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path6/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path6/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBiHHCYWFknV"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "IHnvee6QJacj"
      },
      "source": [
        "def layer_6_param_init():\n",
        "    w1 = randn(3000, 1000) / math.sqrt(1000)\n",
        "    w2 = randn(1000, 500) / math.sqrt(500)\n",
        "    w3 = randn(500, 300) / math.sqrt(300)\n",
        "    w4 = randn(300, 100) / math.sqrt(100)\n",
        "    w5 = randn(100, 50) / math.sqrt(50)\n",
        "    w6 = randn(50, 7) / math.sqrt(7)\n",
        "    b1 = randn(1000)\n",
        "    b2 = randn(500)\n",
        "    b3 = randn(300)\n",
        "    b4 = randn(100)\n",
        "    b5 = randn(50)\n",
        "    b6 = randn(7)\n",
        "    return w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6\n",
        "\n",
        "    \n",
        "def layer_6(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        start_epoch = time()\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                start_bs = time()\n",
        "\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset(3000)\n",
        "                w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6 = layer_6_param_init()\n",
        "                model = DummyModel(6, w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))\n",
        "\n",
        "                print(f\"done, epoch: {epoch}, lr: {lr}, bs: {bs}\")\n",
        "                \n",
        "                print(f\"took {time()-start_bs} seconds for a one batch\")\n",
        "\n",
        "        print(f\"took {time()-start_epoch} seconds for an epoch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZGR7J5yDJHj6"
      },
      "source": [
        "layer_6(epochs = epochs, lrs =lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVNiC6l69g2u"
      },
      "source": [
        "!cp -R /content/stats/maxlen3000/6layer /gdrive/MyDrive/2021/TL/midterm/hyper_stats/maxlen3000/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJAe6BkZJXbu"
      },
      "source": [
        "## when layer == 4 (3000 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YFy99vBdGgpA"
      },
      "source": [
        "path4 = max1_path/'4layer'; path4.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path4/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path4/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6yFRJSyF7VG"
      },
      "source": [
        "def layer_4_param_init():\n",
        "    m, h, l, q = 3000, 145, 32, 15\n",
        "    w1 = randn(m, h) / math.sqrt(h)\n",
        "    w2 = randn(h, l) / math.sqrt(l)\n",
        "    w3 = randn(l, q) / math.sqrt(q)\n",
        "    w4 = randn(q, c) / math.sqrt(c)\n",
        "    \n",
        "    b1 = randn(h)\n",
        "    b2 = randn(l)\n",
        "    b3 = randn(q)\n",
        "    b4 = randn(c)\n",
        "    \n",
        "    return w1, b1, w2, b2, w3, b3, w4, b4\n",
        "\n",
        "    \n",
        "def layer_4(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        start_epoch = time()\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                start_bs = time()\n",
        "                \n",
        "                x_train, y_train, x_valid, y_valid = init_dataset(3000)\n",
        "                w1, b1, w2, b2, w3, b3, w4, b4 = layer_4_param_init()\n",
        "                model = DummyModel(4, w1, b1, w2, b2, w3, b3, w4, b4)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))   \n",
        "                print(f\"done, epoch: {epoch}, lr: {lr}, bs: {bs}\")\n",
        "                \n",
        "                print(f\"took {time()-start_bs} seconds for a one batch\")\n",
        "\n",
        "        print(f\"took {time()-start_epoch} seconds for an epoch\")                 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wEHr7DtYJJA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb18ca1d-3027-4a0a-f225-d94f649abd33"
      },
      "source": [
        "layer_4(epochs = epochs, lrs =lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done, epoch: 13, lr: 0.025000000075, bs: 16\n",
            "took 33.091715812683105 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.025000000075, bs: 32\n",
            "took 28.6784451007843 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.025000000075, bs: 64\n",
            "took 26.596705198287964 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.01250000008749999, bs: 16\n",
            "took 33.95372486114502 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.01250000008749999, bs: 32\n",
            "took 28.771820306777954 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.01250000008749999, bs: 64\n",
            "took 41.842331409454346 seconds for a one batch\n",
            "done, epoch: 13, lr: 1e-10, bs: 16\n",
            "took 34.12994360923767 seconds for a one batch\n",
            "done, epoch: 13, lr: 1e-10, bs: 32\n",
            "took 28.965757369995117 seconds for a one batch\n",
            "done, epoch: 13, lr: 1e-10, bs: 64\n",
            "took 26.841758728027344 seconds for a one batch\n",
            "took 865.741170167923 seconds for an epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h5IYuZe7XBug"
      },
      "source": [
        "!cp -R /content/stats/maxlen3000/4layer /gdrive/MyDrive/2021/TL/midterm/hyper_stats/maxlen3000/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SrWlD4XhH7wT"
      },
      "source": [
        "# when max length = 1000\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tX9DWYWH7wg"
      },
      "source": [
        "max2_path = Path('/content/maxlen1000'); max2_path.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tv6RwcBmH7wh"
      },
      "source": [
        "## when layer == 6\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AG1Ib8qH7wh"
      },
      "source": [
        "path6 = max2_path/'6layer'; path6.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path6/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path6/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5CnV4CxH7wh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "DVnqypauH7wh"
      },
      "source": [
        "def layer_6_param_init():\n",
        "    w1 = randn(1000, 500) / math.sqrt(500)\n",
        "    w2 = randn(500, 300) / math.sqrt(300)\n",
        "    w3 = randn(300, 100) / math.sqrt(100)\n",
        "    w4 = randn(100, 70) / math.sqrt(70)\n",
        "    w5 = randn(70, 20) / math.sqrt(20)\n",
        "    w6 = randn(50, 7) / math.sqrt(7)\n",
        "    b1 = randn(500)\n",
        "    b2 = randn(300)\n",
        "    b3 = randn(100)\n",
        "    b4 = randn(70)\n",
        "    b5 = randn(20)\n",
        "    b6 = randn(7)\n",
        "    return w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6\n",
        "\n",
        "    \n",
        "def layer_6(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset()\n",
        "                w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6 = layer_6_param_init()\n",
        "                model = DummyModel(6, w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6brnv7IH7wh"
      },
      "source": [
        "layer_2(epochs = epochs, lrs =lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HM8WWZKeH7wi"
      },
      "source": [
        "## when layer == 4 (3000 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW6K-_GKH7wi"
      },
      "source": [
        "path4 = max1_path/'4layer'; path4.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path4/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path4/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KTIHyxeH7wi"
      },
      "source": [
        "def layer_4_param_init():\n",
        "    m, h, l, q = 3000, 145, 32, 15\n",
        "    w1 = randn(m, h) / math.sqrt(h)\n",
        "    w2 = randn(h, l) / math.sqrt(l)\n",
        "    w3 = randn(l, q) / math.sqrt(q)\n",
        "    w4 = randn(q, c) / math.sqrt(c)\n",
        "    \n",
        "    b1 = randn(h)\n",
        "    b2 = randn(l)\n",
        "    b3 = randn(q)\n",
        "    b4 = randn(c)\n",
        "    \n",
        "    return w1, b1, w2, b2, w3, b3, w4, b4\n",
        "\n",
        "    \n",
        "def layer_4(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset()\n",
        "                w1, b1, w2, b2, w3, b3, w4, b4 = layer_4_param_init()\n",
        "                model = DummyModel(6, w1, b1, w2, b2, w3, b3, w4, b4)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04goHgZjH7wi"
      },
      "source": [
        "## when layer == 2 (3000 features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBzGGskfH7wi"
      },
      "source": [
        "path2 = max1_path/'2layer'; path2.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path2/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path2/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1usFRWxiH7wj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "kUicmm5rH7wj"
      },
      "source": [
        "def layer_2_param_init():\n",
        "    w1 = randn(3000, 1000) / math.sqrt(1000)\n",
        "    w2 = randn(1000, 500) / math.sqrt(500)\n",
        "    w3 = randn(500, 300) / math.sqrt(300)\n",
        "    w4 = randn(300, 100) / math.sqrt(100)\n",
        "    w5 = randn(100, 50) / math.sqrt(50)\n",
        "    w6 = randn(50, 7) / math.sqrt(7)\n",
        "    b1 = randn(1000)\n",
        "    b2 = randn(500)\n",
        "    b3 = randn(300)\n",
        "    b4 = randn(100)\n",
        "    b5 = randn(50)\n",
        "    b6 = randn(7)\n",
        "    return w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6\n",
        "\n",
        "    \n",
        "def layer_2(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset()\n",
        "                w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6 = layer_6_param_init()\n",
        "                model = DummyModel(6, w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdLtVMNrH7wj"
      },
      "source": [
        "layer_6(epochs = epochs, lrs =lrs, batches = batches)\n",
        "layer_4(epochs = epochs, lrs =lrs, batches = batches)\n",
        "layer_2(epochs = epochs, lrs =lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RF7DOBOwIC-A"
      },
      "source": [
        "# when max length = 100\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8ow76yJIC-B"
      },
      "source": [
        "lrs = np.linspace(1e-1, 1e-10, 9)\n",
        "epochs = range(1, 15, 2)\n",
        "batches = [16,32,64]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41csSzrmIC-B"
      },
      "source": [
        "max3_path = Path('/content/maxlen100'); max1_path.mkdir(parents=True, exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i6dRr0WIC-B"
      },
      "source": [
        "## when layer == 6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-bSL0GUIC-B"
      },
      "source": [
        "path6 = max3_path/'6layer'; path6.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path6/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path6/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HQefscQIC-C"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "AxbxtsS4IC-C"
      },
      "source": [
        "def layer_6_param_init():\n",
        "    w1 = randn(100, 70) / math.sqrt(70)\n",
        "    w2 = randn(70, 50) / math.sqrt(50)\n",
        "    w3 = randn(50, 30) / math.sqrt(30)\n",
        "    w4 = randn(30, 20) / math.sqrt(20)\n",
        "    w5 = randn(20, 10) / math.sqrt(10)\n",
        "    w6 = randn(10, 7) / math.sqrt(7)\n",
        "\n",
        "    b1 = randn(70)\n",
        "    b2 = randn(50)\n",
        "    b3 = randn(30)\n",
        "    b4 = randn(20)\n",
        "    b5 = randn(10)\n",
        "    b6 = randn(7)\n",
        "    return w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6\n",
        "\n",
        "    \n",
        "def layer_6(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset(100)\n",
        "                w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6 = layer_6_param_init()\n",
        "                model = DummyModel(6, w1, b1, w2, b2, w3, b3, w4, b4, w5, b5, w6, b6)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))\n",
        "        print(f'{epoch} done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LRnFjjoIC-C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "outputId": "989a186d-0d05-4c4c-8815-8ba4e1c3519c"
      },
      "source": [
        "layer_6(epochs = epochs, lrs =lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 done\n",
            "3 done\n",
            "5 done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-147-26fe89dc2861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlayer_6\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlrs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-146-b44e2e316297>\u001b[0m in \u001b[0;36mlayer_6\u001b[0;34m(epochs, lrs, batches)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mrunner\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRunner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m                 \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m                 \u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0mparams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-428f6c9d9ecc>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, epochs, bs, lr)\u001b[0m\n\u001b[1;32m     33\u001b[0m                 \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1c8572c58189>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pred, y)\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m#P(\\hat{y})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_p_yhat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_p_yhat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-17-1c8572c58189>\u001b[0m in \u001b[0;36mnll\u001b[0;34m(self, pred, y)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# print(pred.shape, y.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHA0pq8GIC-D"
      },
      "source": [
        "## when layer == 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_Ok5b5PIC-D"
      },
      "source": [
        "path4 = max3_path/'4layer'; path4.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path4/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path4/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DIHbry8IC-D"
      },
      "source": [
        "def layer_4_param_init():\n",
        "    m, h, l, q = 100, 74, 32, 15\n",
        "    w1 = randn(m, h) / math.sqrt(h)\n",
        "    w2 = randn(h, l) / math.sqrt(l)\n",
        "    w3 = randn(l, q) / math.sqrt(q)\n",
        "    w4 = randn(q, c) / math.sqrt(c)\n",
        "    \n",
        "    b1 = randn(h)\n",
        "    b2 = randn(l)\n",
        "    b3 = randn(q)\n",
        "    b4 = randn(c)\n",
        "    \n",
        "    return w1, b1, w2, b2, w3, b3, w4, b4\n",
        "\n",
        "    \n",
        "def layer_4(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        start_epoch = time()\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset(100)\n",
        "                w1, b1, w2, b2, w3, b3, w4, b4 = layer_4_param_init()\n",
        "                model = DummyModel(4, w1, b1, w2, b2, w3, b3, w4, b4)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))\n",
        "        print(f\"took {time()-start_epoch} seconds for an epoch\")                   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLSOB-kKq8_i"
      },
      "source": [
        "layer_4(epochs = epochs, lrs =lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqm-AQM2IC-D"
      },
      "source": [
        "## when layer == 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqHufEpBIC-D"
      },
      "source": [
        "path2 = max3_path/'2layer'; path2.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path2/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path2/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmowpqf8IC-D"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "tBlsfzcPIC-E"
      },
      "source": [
        "def layer_2_param_init():\n",
        "    w1 = randn(100, 50) / math.sqrt(50)\n",
        "    w2 = randn(50, 7) / math.sqrt(7)\n",
        "    \n",
        "    b1 = randn(50)\n",
        "    b2 = randn(7)\n",
        "    return w1, b1, w2, b2\n",
        "\n",
        "def layer_2(epochs, lrs, batches):\n",
        "    for epoch in epochs:\n",
        "        start_epoch = time()\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                start_bs = time()\n",
        "                x_train, y_train, x_valid, y_valid = init_dataset(100)\n",
        "                w1, b1, w2, b2 = layer_2_param_init()\n",
        "                model = DummyModel(2, w1, b1, w2, b2)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_valid, y_valid), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                res.to_csv(fscore_path/(params+'.csv'))\n",
        "                print(f\"done, epoch: {epoch}, lr: {lr}, bs: {bs}\")\n",
        "                \n",
        "                print(f\"took {time()-start_bs} seconds for a one batch\")\n",
        "\n",
        "        print(f\"took {time()-start_epoch} seconds for an epoch\")                    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kerByfIZIC-E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "outputId": "ff727501-5a1b-4976-d49f-9d13d0e50f60"
      },
      "source": [
        "layer_2(epochs = epochs, lrs =lrs, batches = batches)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "done, epoch: 1, lr: 0.1, bs: 16\n",
            "took 1.3811936378479004 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.1, bs: 32\n",
            "took 1.1939911842346191 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.1, bs: 64\n",
            "took 1.1014063358306885 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.08750000001250001, bs: 16\n",
            "took 1.3053853511810303 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.08750000001250001, bs: 32\n",
            "took 1.1368801593780518 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.08750000001250001, bs: 64\n",
            "took 1.134117841720581 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.075000000025, bs: 16\n",
            "took 1.2916254997253418 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.075000000025, bs: 32\n",
            "took 1.289280891418457 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.075000000025, bs: 64\n",
            "took 1.1290781497955322 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.0625000000375, bs: 16\n",
            "took 1.3318629264831543 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.0625000000375, bs: 32\n",
            "took 1.1390423774719238 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.0625000000375, bs: 64\n",
            "took 1.1041462421417236 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.05000000005, bs: 16\n",
            "took 1.3177292346954346 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.05000000005, bs: 32\n",
            "took 1.156707525253296 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.05000000005, bs: 64\n",
            "took 1.1122941970825195 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.0375000000625, bs: 16\n",
            "took 1.285118818283081 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.0375000000625, bs: 32\n",
            "took 1.169226884841919 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.0375000000625, bs: 64\n",
            "took 1.1249895095825195 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.025000000075, bs: 16\n",
            "took 1.2850747108459473 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.025000000075, bs: 32\n",
            "took 1.220621109008789 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.025000000075, bs: 64\n",
            "took 1.1742675304412842 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.01250000008749999, bs: 16\n",
            "took 1.2833914756774902 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.01250000008749999, bs: 32\n",
            "took 1.2018406391143799 seconds for a one batch\n",
            "done, epoch: 1, lr: 0.01250000008749999, bs: 64\n",
            "took 1.1437749862670898 seconds for a one batch\n",
            "done, epoch: 1, lr: 1e-10, bs: 16\n",
            "took 1.2218122482299805 seconds for a one batch\n",
            "done, epoch: 1, lr: 1e-10, bs: 32\n",
            "took 1.1473984718322754 seconds for a one batch\n",
            "done, epoch: 1, lr: 1e-10, bs: 64\n",
            "took 1.1070024967193604 seconds for a one batch\n",
            "took 32.49345660209656 seconds for an epoch\n",
            "done, epoch: 3, lr: 0.1, bs: 16\n",
            "took 1.7155306339263916 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.1, bs: 32\n",
            "took 1.3954904079437256 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.1, bs: 64\n",
            "took 1.3473329544067383 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.08750000001250001, bs: 16\n",
            "took 1.756446361541748 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.08750000001250001, bs: 32\n",
            "took 1.4400651454925537 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.08750000001250001, bs: 64\n",
            "took 1.2156965732574463 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.075000000025, bs: 16\n",
            "took 1.746020793914795 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.075000000025, bs: 32\n",
            "took 1.4938819408416748 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.075000000025, bs: 64\n",
            "took 1.293259859085083 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.0625000000375, bs: 16\n",
            "took 1.772404432296753 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.0625000000375, bs: 32\n",
            "took 1.4265944957733154 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.0625000000375, bs: 64\n",
            "took 1.2716495990753174 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.05000000005, bs: 16\n",
            "took 1.9175751209259033 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.05000000005, bs: 32\n",
            "took 1.472980260848999 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.05000000005, bs: 64\n",
            "took 1.2866947650909424 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.0375000000625, bs: 16\n",
            "took 1.7947866916656494 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.0375000000625, bs: 32\n",
            "took 1.4849095344543457 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.0375000000625, bs: 64\n",
            "took 1.3076262474060059 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.025000000075, bs: 16\n",
            "took 1.8866159915924072 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.025000000075, bs: 32\n",
            "took 1.4401745796203613 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.025000000075, bs: 64\n",
            "took 1.3572988510131836 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.01250000008749999, bs: 16\n",
            "took 1.92765474319458 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.01250000008749999, bs: 32\n",
            "took 1.5018203258514404 seconds for a one batch\n",
            "done, epoch: 3, lr: 0.01250000008749999, bs: 64\n",
            "took 1.314995527267456 seconds for a one batch\n",
            "done, epoch: 3, lr: 1e-10, bs: 16\n",
            "took 1.828965663909912 seconds for a one batch\n",
            "done, epoch: 3, lr: 1e-10, bs: 32\n",
            "took 1.4944641590118408 seconds for a one batch\n",
            "done, epoch: 3, lr: 1e-10, bs: 64\n",
            "took 1.2308883666992188 seconds for a one batch\n",
            "took 41.12592530250549 seconds for an epoch\n",
            "done, epoch: 5, lr: 0.1, bs: 16\n",
            "took 2.229268789291382 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.1, bs: 32\n",
            "took 1.7551040649414062 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.1, bs: 64\n",
            "took 1.430511236190796 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.08750000001250001, bs: 16\n",
            "took 2.226938247680664 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.08750000001250001, bs: 32\n",
            "took 1.8398847579956055 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.08750000001250001, bs: 64\n",
            "took 1.4491462707519531 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.075000000025, bs: 16\n",
            "took 2.2015445232391357 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.075000000025, bs: 32\n",
            "took 1.6663060188293457 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.075000000025, bs: 64\n",
            "took 1.4638359546661377 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.0625000000375, bs: 16\n",
            "took 2.43642258644104 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.0625000000375, bs: 32\n",
            "took 1.7954590320587158 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.0625000000375, bs: 64\n",
            "took 1.4488277435302734 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.05000000005, bs: 16\n",
            "took 2.2887775897979736 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.05000000005, bs: 32\n",
            "took 1.7811899185180664 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.05000000005, bs: 64\n",
            "took 1.409132719039917 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.0375000000625, bs: 16\n",
            "took 2.328805446624756 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.0375000000625, bs: 32\n",
            "took 1.7603654861450195 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.0375000000625, bs: 64\n",
            "took 1.4878332614898682 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.025000000075, bs: 16\n",
            "took 2.258007287979126 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.025000000075, bs: 32\n",
            "took 1.8380849361419678 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.025000000075, bs: 64\n",
            "took 1.5083074569702148 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.01250000008749999, bs: 16\n",
            "took 2.2196457386016846 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.01250000008749999, bs: 32\n",
            "took 1.8410398960113525 seconds for a one batch\n",
            "done, epoch: 5, lr: 0.01250000008749999, bs: 64\n",
            "took 1.4767649173736572 seconds for a one batch\n",
            "done, epoch: 5, lr: 1e-10, bs: 16\n",
            "took 2.1413564682006836 seconds for a one batch\n",
            "done, epoch: 5, lr: 1e-10, bs: 32\n",
            "took 1.6806130409240723 seconds for a one batch\n",
            "done, epoch: 5, lr: 1e-10, bs: 64\n",
            "took 1.443173885345459 seconds for a one batch\n",
            "took 49.40966606140137 seconds for an epoch\n",
            "done, epoch: 7, lr: 0.1, bs: 16\n",
            "took 2.712144374847412 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.1, bs: 32\n",
            "took 1.9313905239105225 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.1, bs: 64\n",
            "took 1.6644947528839111 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.08750000001250001, bs: 16\n",
            "took 2.619755268096924 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.08750000001250001, bs: 32\n",
            "took 2.0566961765289307 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.08750000001250001, bs: 64\n",
            "took 1.5757803916931152 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.075000000025, bs: 16\n",
            "took 2.674121618270874 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.075000000025, bs: 32\n",
            "took 2.129476547241211 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.075000000025, bs: 64\n",
            "took 1.623110294342041 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.0625000000375, bs: 16\n",
            "took 2.9411261081695557 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.0625000000375, bs: 32\n",
            "took 2.08711838722229 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.0625000000375, bs: 64\n",
            "took 1.6282241344451904 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.05000000005, bs: 16\n",
            "took 2.7562177181243896 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.05000000005, bs: 32\n",
            "took 1.9958231449127197 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.05000000005, bs: 64\n",
            "took 1.6238689422607422 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.0375000000625, bs: 16\n",
            "took 2.7291951179504395 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.0375000000625, bs: 32\n",
            "took 1.9936065673828125 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.0375000000625, bs: 64\n",
            "took 1.7073066234588623 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.025000000075, bs: 16\n",
            "took 2.650966167449951 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.025000000075, bs: 32\n",
            "took 2.1070799827575684 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.025000000075, bs: 64\n",
            "took 1.6490325927734375 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.01250000008749999, bs: 16\n",
            "took 2.660696506500244 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.01250000008749999, bs: 32\n",
            "took 2.1536309719085693 seconds for a one batch\n",
            "done, epoch: 7, lr: 0.01250000008749999, bs: 64\n",
            "took 1.6402971744537354 seconds for a one batch\n",
            "done, epoch: 7, lr: 1e-10, bs: 16\n",
            "took 2.6715943813323975 seconds for a one batch\n",
            "done, epoch: 7, lr: 1e-10, bs: 32\n",
            "took 1.956864356994629 seconds for a one batch\n",
            "done, epoch: 7, lr: 1e-10, bs: 64\n",
            "took 1.6082699298858643 seconds for a one batch\n",
            "took 57.55233073234558 seconds for an epoch\n",
            "done, epoch: 9, lr: 0.1, bs: 16\n",
            "took 3.1681594848632812 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.1, bs: 32\n",
            "took 2.2237958908081055 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.1, bs: 64\n",
            "took 1.7527885437011719 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.08750000001250001, bs: 16\n",
            "took 3.317375421524048 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.08750000001250001, bs: 32\n",
            "took 2.3869214057922363 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.08750000001250001, bs: 64\n",
            "took 1.8080244064331055 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.075000000025, bs: 16\n",
            "took 3.2056779861450195 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.075000000025, bs: 32\n",
            "took 2.205568790435791 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.075000000025, bs: 64\n",
            "took 1.7344279289245605 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.0625000000375, bs: 16\n",
            "took 3.1413867473602295 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.0625000000375, bs: 32\n",
            "took 2.273986577987671 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.0625000000375, bs: 64\n",
            "took 1.7129437923431396 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.05000000005, bs: 16\n",
            "took 3.1892504692077637 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.05000000005, bs: 32\n",
            "took 2.2624573707580566 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.05000000005, bs: 64\n",
            "took 1.8272490501403809 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.0375000000625, bs: 16\n",
            "took 3.410670042037964 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.0375000000625, bs: 32\n",
            "took 2.374868154525757 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.0375000000625, bs: 64\n",
            "took 1.7931606769561768 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.025000000075, bs: 16\n",
            "took 3.271766185760498 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.025000000075, bs: 32\n",
            "took 2.258347511291504 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.025000000075, bs: 64\n",
            "took 1.8589186668395996 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.01250000008749999, bs: 16\n",
            "took 3.20444655418396 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.01250000008749999, bs: 32\n",
            "took 2.2784221172332764 seconds for a one batch\n",
            "done, epoch: 9, lr: 0.01250000008749999, bs: 64\n",
            "took 1.8780803680419922 seconds for a one batch\n",
            "done, epoch: 9, lr: 1e-10, bs: 16\n",
            "took 3.0143232345581055 seconds for a one batch\n",
            "done, epoch: 9, lr: 1e-10, bs: 32\n",
            "took 2.3324902057647705 seconds for a one batch\n",
            "done, epoch: 9, lr: 1e-10, bs: 64\n",
            "took 1.732703447341919 seconds for a one batch\n",
            "took 65.62034940719604 seconds for an epoch\n",
            "done, epoch: 11, lr: 0.1, bs: 16\n",
            "took 3.632448673248291 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.1, bs: 32\n",
            "took 2.5514273643493652 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.1, bs: 64\n",
            "took 1.894425392150879 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.08750000001250001, bs: 16\n",
            "took 3.706796884536743 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.08750000001250001, bs: 32\n",
            "took 2.4126625061035156 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.08750000001250001, bs: 64\n",
            "took 1.968308925628662 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.075000000025, bs: 16\n",
            "took 3.832420825958252 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.075000000025, bs: 32\n",
            "took 2.7475485801696777 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.075000000025, bs: 64\n",
            "took 1.9268653392791748 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.0625000000375, bs: 16\n",
            "took 3.6041641235351562 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.0625000000375, bs: 32\n",
            "took 2.6211965084075928 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.0625000000375, bs: 64\n",
            "took 1.9015727043151855 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.05000000005, bs: 16\n",
            "took 3.601505756378174 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.05000000005, bs: 32\n",
            "took 2.4927570819854736 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.05000000005, bs: 64\n",
            "took 2.0614657402038574 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.0375000000625, bs: 16\n",
            "took 3.635896921157837 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.0375000000625, bs: 32\n",
            "took 2.4996659755706787 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.0375000000625, bs: 64\n",
            "took 1.9160785675048828 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.025000000075, bs: 16\n",
            "took 3.74416184425354 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.025000000075, bs: 32\n",
            "took 2.494422435760498 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.025000000075, bs: 64\n",
            "took 1.9393577575683594 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.01250000008749999, bs: 16\n",
            "took 3.6470606327056885 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.01250000008749999, bs: 32\n",
            "took 2.5899457931518555 seconds for a one batch\n",
            "done, epoch: 11, lr: 0.01250000008749999, bs: 64\n",
            "took 1.9628736972808838 seconds for a one batch\n",
            "done, epoch: 11, lr: 1e-10, bs: 16\n",
            "took 3.547250509262085 seconds for a one batch\n",
            "done, epoch: 11, lr: 1e-10, bs: 32\n",
            "took 2.5059661865234375 seconds for a one batch\n",
            "done, epoch: 11, lr: 1e-10, bs: 64\n",
            "took 2.021063804626465 seconds for a one batch\n",
            "took 73.46462607383728 seconds for an epoch\n",
            "done, epoch: 13, lr: 0.1, bs: 16\n",
            "took 4.065605878829956 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.1, bs: 32\n",
            "took 2.702591896057129 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.1, bs: 64\n",
            "took 2.1658613681793213 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.08750000001250001, bs: 16\n",
            "took 4.065973281860352 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.08750000001250001, bs: 32\n",
            "took 2.826969623565674 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.08750000001250001, bs: 64\n",
            "took 2.088303327560425 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.075000000025, bs: 16\n",
            "took 4.103095531463623 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.075000000025, bs: 32\n",
            "took 2.8022377490997314 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.075000000025, bs: 64\n",
            "took 2.0883071422576904 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.0625000000375, bs: 16\n",
            "took 4.100802659988403 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.0625000000375, bs: 32\n",
            "took 2.9604859352111816 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.0625000000375, bs: 64\n",
            "took 2.0666017532348633 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.05000000005, bs: 16\n",
            "took 4.112856864929199 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.05000000005, bs: 32\n",
            "took 3.007542610168457 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.05000000005, bs: 64\n",
            "took 2.224492073059082 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.0375000000625, bs: 16\n",
            "took 4.398541450500488 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.0375000000625, bs: 32\n",
            "took 3.020068645477295 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.0375000000625, bs: 64\n",
            "took 2.1544911861419678 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.025000000075, bs: 16\n",
            "took 4.151108741760254 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.025000000075, bs: 32\n",
            "took 2.9517760276794434 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.025000000075, bs: 64\n",
            "took 2.3801729679107666 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.01250000008749999, bs: 16\n",
            "took 4.157092332839966 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.01250000008749999, bs: 32\n",
            "took 2.832876443862915 seconds for a one batch\n",
            "done, epoch: 13, lr: 0.01250000008749999, bs: 64\n",
            "took 2.157491683959961 seconds for a one batch\n",
            "done, epoch: 13, lr: 1e-10, bs: 16\n",
            "took 4.236619234085083 seconds for a one batch\n",
            "done, epoch: 13, lr: 1e-10, bs: 32\n",
            "took 2.7661373615264893 seconds for a one batch\n",
            "done, epoch: 13, lr: 1e-10, bs: 64\n",
            "took 2.124241828918457 seconds for a one batch\n",
            "took 82.71623253822327 seconds for an epoch\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMN2v2Tk528H"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yov9IZmyIC-E"
      },
      "source": [
        "!cp -R /content/maxlen100/6layer /gdrive/MyDrive/2021/TL/midterm/hyper_stats/maxlen100/."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oYIWIwgTFvm"
      },
      "source": [
        "# This is the specific experiment executed on Jun 3, to check biased results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5WhVSlmTFvj"
      },
      "source": [
        "path2 = max1_path/'2layer'; path2.mkdir(parents=True, exist_ok=True)\n",
        "fscore_path = path2/'fscore'; fscore_path.mkdir(parents=1, exist_ok=1)\n",
        "mean_val_path = path2/'meanval'; mean_val_path.mkdir(parents=1, exist_ok=1)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HxhL2KtgTFvj"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbcErL2-TFvk"
      },
      "source": [
        "x_train, y_train, x_test, y_test = init_dataset(3000, 1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAUeAaBzTFvk",
        "outputId": "97e2f0da-386c-445c-9bc8-3d126ce458a4"
      },
      "source": [
        "x_test.shape"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1121, 3000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2GMKBtWTFvl",
        "outputId": "4190b49b-f282-4ac7-bd4c-5324a5cf0fb0"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1121, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ssUkGxtOT9J5"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "fqw8xM3OTFvl"
      },
      "source": [
        "def layer_2_param_init():\n",
        "    w1 = randn(3000, 100) / math.sqrt(100)\n",
        "    w2 = randn(100, 7) / math.sqrt(7)\n",
        "\n",
        "    b1 = randn(100)\n",
        "    b2 = randn(7)\n",
        "\n",
        "    return w1, b1, w2, b2\n",
        "\n",
        "def layer_2(epochs, lrs, batches):\n",
        "    ranks = []\n",
        "    for epoch in epochs:\n",
        "        start_epoch = time()\n",
        "        for lr in lrs:\n",
        "            for bs in batches:\n",
        "                start_bs = time()\n",
        "                x_train, y_train, x_test, y_test = init_dataset(3000, 1)\n",
        "                w1, b1, w2, b2 = layer_2_param_init()\n",
        "                model = DummyModel(2,w1, b1, w2, b2)\n",
        "                \n",
        "                runner = Runner((x_train, y_train), (x_test, y_test), model)                \n",
        "                runner.train(epochs = epoch, bs = bs, lr = lr)\n",
        "                res, stats = runner.evaluate()\n",
        "                params = f'_lr{lr:.3f}_bs{bs}_epoch{epoch}'\n",
        "                with open(mean_val_path/(params+'.pkl'), 'wb') as f:\n",
        "                    pickle.dump(stats, file = f)\n",
        "                res['lr'], res['bs'], res['epoch'] = lr, bs, epoch\n",
        "                # res.to_csv(fscore_path/(params+'.csv'))\n",
        "                print(f\"epoch: {epoch}, lr: {lr}, bs: {bs}\")\n",
        "                fscore = torch.tensor(res['f1-score'].to_numpy(dtype=float))\n",
        "                ranks += [fscore.argsort().tolist()]\n",
        "                print()\n",
        "                print(''.join(['-']*20))\n",
        "                \n",
        "                \n",
        "                print(f\"took {time()-start_bs} seconds for a one batch\")\n",
        "        print(f'{time() - start_epoch}')\n",
        "    return ranks\n",
        " "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1KlQ3v7TFvm",
        "outputId": "69558cb5-453a-4d03-9593-fc2bb8f75c59"
      },
      "source": [
        "rankings = layer_2(epochs = range(4,8), lrs = lrs, batches = [16, 32, 64])       "
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 4, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.8106935024261475 seconds for a one batch\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch: 4, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.7002551555633545 seconds for a one batch\n",
            "epoch: 4, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.403634071350098 seconds for a one batch\n",
            "epoch: 4, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.6862311363220215 seconds for a one batch\n",
            "epoch: 4, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.6622278690338135 seconds for a one batch\n",
            "epoch: 4, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.2039220333099365 seconds for a one batch\n",
            "epoch: 4, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.732692718505859 seconds for a one batch\n",
            "epoch: 4, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.594966888427734 seconds for a one batch\n",
            "epoch: 4, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.238487958908081 seconds for a one batch\n",
            "epoch: 4, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.310553312301636 seconds for a one batch\n",
            "epoch: 4, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.747560739517212 seconds for a one batch\n",
            "epoch: 4, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.29375147819519 seconds for a one batch\n",
            "epoch: 4, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.470308303833008 seconds for a one batch\n",
            "epoch: 4, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.666008234024048 seconds for a one batch\n",
            "epoch: 4, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.306798219680786 seconds for a one batch\n",
            "epoch: 4, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.348089933395386 seconds for a one batch\n",
            "epoch: 4, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.695587873458862 seconds for a one batch\n",
            "epoch: 4, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.28685736656189 seconds for a one batch\n",
            "epoch: 4, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.355189323425293 seconds for a one batch\n",
            "epoch: 4, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.647488832473755 seconds for a one batch\n",
            "epoch: 4, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.57004189491272 seconds for a one batch\n",
            "epoch: 4, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.9118053913116455 seconds for a one batch\n",
            "epoch: 4, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.262360334396362 seconds for a one batch\n",
            "epoch: 4, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.8667426109313965 seconds for a one batch\n",
            "epoch: 4, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 6.438622713088989 seconds for a one batch\n",
            "epoch: 4, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 5.76261830329895 seconds for a one batch\n",
            "epoch: 4, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 5.3197596073150635 seconds for a one batch\n",
            "159.29549765586853\n",
            "epoch: 5, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.877143383026123 seconds for a one batch\n",
            "epoch: 5, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.886152267456055 seconds for a one batch\n",
            "epoch: 5, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.3927319049835205 seconds for a one batch\n",
            "epoch: 5, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.887068510055542 seconds for a one batch\n",
            "epoch: 5, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.947818994522095 seconds for a one batch\n",
            "epoch: 5, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.408283472061157 seconds for a one batch\n",
            "epoch: 5, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.825303792953491 seconds for a one batch\n",
            "epoch: 5, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.949322462081909 seconds for a one batch\n",
            "epoch: 5, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.369048833847046 seconds for a one batch\n",
            "epoch: 5, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.716584920883179 seconds for a one batch\n",
            "epoch: 5, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.898338079452515 seconds for a one batch\n",
            "epoch: 5, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.262917757034302 seconds for a one batch\n",
            "epoch: 5, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.741909980773926 seconds for a one batch\n",
            "epoch: 5, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 7.001452207565308 seconds for a one batch\n",
            "epoch: 5, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.473557710647583 seconds for a one batch\n",
            "epoch: 5, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.687106132507324 seconds for a one batch\n",
            "epoch: 5, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.893195390701294 seconds for a one batch\n",
            "epoch: 5, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.32357931137085 seconds for a one batch\n",
            "epoch: 5, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.7750890254974365 seconds for a one batch\n",
            "epoch: 5, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.964189291000366 seconds for a one batch\n",
            "epoch: 5, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.434799909591675 seconds for a one batch\n",
            "epoch: 5, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.74077033996582 seconds for a one batch\n",
            "epoch: 5, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.886639833450317 seconds for a one batch\n",
            "epoch: 5, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.357506036758423 seconds for a one batch\n",
            "epoch: 5, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 7.888550043106079 seconds for a one batch\n",
            "epoch: 5, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 6.931903123855591 seconds for a one batch\n",
            "epoch: 5, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 6.396554231643677 seconds for a one batch\n",
            "189.92002606391907\n",
            "epoch: 6, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.24122142791748 seconds for a one batch\n",
            "epoch: 6, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.033012628555298 seconds for a one batch\n",
            "epoch: 6, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.360854625701904 seconds for a one batch\n",
            "epoch: 6, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.245888233184814 seconds for a one batch\n",
            "epoch: 6, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.10824704170227 seconds for a one batch\n",
            "epoch: 6, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.482787609100342 seconds for a one batch\n",
            "epoch: 6, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.09932565689087 seconds for a one batch\n",
            "epoch: 6, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.100733757019043 seconds for a one batch\n",
            "epoch: 6, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.367337226867676 seconds for a one batch\n",
            "epoch: 6, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.184942483901978 seconds for a one batch\n",
            "epoch: 6, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.230947494506836 seconds for a one batch\n",
            "epoch: 6, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.502957105636597 seconds for a one batch\n",
            "epoch: 6, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.123178243637085 seconds for a one batch\n",
            "epoch: 6, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.113595485687256 seconds for a one batch\n",
            "epoch: 6, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.487226724624634 seconds for a one batch\n",
            "epoch: 6, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 8.99580454826355 seconds for a one batch\n",
            "epoch: 6, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.155163049697876 seconds for a one batch\n",
            "epoch: 6, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.506375074386597 seconds for a one batch\n",
            "epoch: 6, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.3537757396698 seconds for a one batch\n",
            "epoch: 6, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.172846555709839 seconds for a one batch\n",
            "epoch: 6, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.519056081771851 seconds for a one batch\n",
            "epoch: 6, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.05746078491211 seconds for a one batch\n",
            "epoch: 6, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.226105451583862 seconds for a one batch\n",
            "epoch: 6, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.5721588134765625 seconds for a one batch\n",
            "epoch: 6, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 9.19614553451538 seconds for a one batch\n",
            "epoch: 6, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 8.192318677902222 seconds for a one batch\n",
            "epoch: 6, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 7.426076173782349 seconds for a one batch\n",
            "223.0594220161438\n",
            "epoch: 7, lr: 0.1, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.481754302978516 seconds for a one batch\n",
            "epoch: 7, lr: 0.1, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.447365999221802 seconds for a one batch\n",
            "epoch: 7, lr: 0.1, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.576030969619751 seconds for a one batch\n",
            "epoch: 7, lr: 0.08750000001250001, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.528336524963379 seconds for a one batch\n",
            "epoch: 7, lr: 0.08750000001250001, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.371083736419678 seconds for a one batch\n",
            "epoch: 7, lr: 0.08750000001250001, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.532692909240723 seconds for a one batch\n",
            "epoch: 7, lr: 0.075000000025, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.592236280441284 seconds for a one batch\n",
            "epoch: 7, lr: 0.075000000025, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.289957284927368 seconds for a one batch\n",
            "epoch: 7, lr: 0.075000000025, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.60942554473877 seconds for a one batch\n",
            "epoch: 7, lr: 0.0625000000375, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.432101726531982 seconds for a one batch\n",
            "epoch: 7, lr: 0.0625000000375, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.284245252609253 seconds for a one batch\n",
            "epoch: 7, lr: 0.0625000000375, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.527282953262329 seconds for a one batch\n",
            "epoch: 7, lr: 0.05000000005, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.377812623977661 seconds for a one batch\n",
            "epoch: 7, lr: 0.05000000005, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.531172513961792 seconds for a one batch\n",
            "epoch: 7, lr: 0.05000000005, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.687767028808594 seconds for a one batch\n",
            "epoch: 7, lr: 0.0375000000625, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.48189902305603 seconds for a one batch\n",
            "epoch: 7, lr: 0.0375000000625, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.41762638092041 seconds for a one batch\n",
            "epoch: 7, lr: 0.0375000000625, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.617358684539795 seconds for a one batch\n",
            "epoch: 7, lr: 0.025000000075, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.745253562927246 seconds for a one batch\n",
            "epoch: 7, lr: 0.025000000075, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.385709285736084 seconds for a one batch\n",
            "epoch: 7, lr: 0.025000000075, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.642090320587158 seconds for a one batch\n",
            "epoch: 7, lr: 0.01250000008749999, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.659449338912964 seconds for a one batch\n",
            "epoch: 7, lr: 0.01250000008749999, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.41622281074524 seconds for a one batch\n",
            "epoch: 7, lr: 0.01250000008749999, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.505283117294312 seconds for a one batch\n",
            "epoch: 7, lr: 1e-10, bs: 16\n",
            "\n",
            "--------------------\n",
            "took 10.271328926086426 seconds for a one batch\n",
            "epoch: 7, lr: 1e-10, bs: 32\n",
            "\n",
            "--------------------\n",
            "took 9.299227714538574 seconds for a one batch\n",
            "epoch: 7, lr: 1e-10, bs: 64\n",
            "\n",
            "--------------------\n",
            "took 8.582528591156006 seconds for a one batch\n",
            "256.29856038093567\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v020EtkiTFvn"
      },
      "source": [
        "rankings = torch.tensor(rankings)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXWkEbqaTFvn",
        "outputId": "ff781da9-79d7-456a-cdd8-1bc35cef96eb"
      },
      "source": [
        "len(rankings[:, 0])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "108"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff-jXvhsTFvn"
      },
      "source": [
        "torch.save(rankings, 'tl2021_7class_fscore_rank.pt')"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "FIUM9AnpTFvn",
        "outputId": "b8cad7ad-d8f6-408c-ef3e-b281319b968e"
      },
      "source": [
        "# from google.colab import files\n",
        "# files.download('tl2021_7class_fscore_rank.pt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_6deee094-a731-4018-8bd1-3d076ce474a3\", \"tl2021_7class_fscore_rank.pt\", 9400)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HoDF3vN1TFvp"
      },
      "source": [
        "idx2emotion = {v.index(1):k for k, v in reference_dict.items()}"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "_VdXtQY0TFvq",
        "outputId": "41e967e4-054e-4745-d4dc-d73fab5c43b2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, axs = plt.subplots(7, figsize=(15,35))\n",
        "fig.suptitle('relative score per emotion')\n",
        "for i in range(7):\n",
        "    axs[i].hist(rankings[:, i])\n",
        "    axs[i].set_title(idx2emotion[i])\n"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1080x2520 with 7 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}