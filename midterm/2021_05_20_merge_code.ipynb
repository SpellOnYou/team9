{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_2021_05_12_merge_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zwxJN-alkO9V",
        "qAr2ogy3sLeW",
        "gRWgXS_wvonM",
        "oT7n4bqFvsa9",
        "Loh79wNZwS_o",
        "i4aEwhi9BjoL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpellOnYou/CLab21/blob/main/midterm/2021_05_20_merge_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxJN-alkO9V"
      },
      "source": [
        "## Enviroment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k232czaeCGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c8545c7-2e14-4f75-94d6-3781e7b9f3ef"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/CLab21.git'.format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: SpellOnYou\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAr2ogy3sLeW"
      },
      "source": [
        "## Pre-processing(text representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9HpXhzDALSn"
      },
      "source": [
        "Comment\n",
        "\n",
        "1. Generally don't need to use external library to read csv. open() function will work.\n",
        "2. Now we read one file twice(1. for sentence padding, 2. one-hot encoding) --> not efficient way to use computation resource :) should consider reconstructuring data loading process.\n",
        "3. Didn't investigate the whole algorithm. But BOW took much time compared to its data size. Need to be checked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRWgXS_wvonM"
      },
      "source": [
        "### x data, tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woGbW17CslSY"
      },
      "source": [
        "import numpy as np\n",
        "import csv\n",
        "\n",
        "\n",
        "class PadMaxLength:\n",
        "\n",
        "    def __init__(self, file_name):\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.list_padded_sentences = []\n",
        "        self.text = []\n",
        "        for col in self.csv_file:\n",
        "            self.text.append(col[\"text\"])\n",
        "\n",
        "    def min_max_sentences(self):\n",
        "        tokenized_sentences = []\n",
        "        # split each sentence into words\n",
        "        for sentence in self.text:\n",
        "            tokens = sentence.split()\n",
        "            tokenized_sentences.append(tokens)\n",
        "        # get longest sentence and its length\n",
        "        longest_sent = max(tokenized_sentences, key=len)\n",
        "        longest_sent_len = len(longest_sent)\n",
        "\n",
        "        # get shortest word and its length\n",
        "        shortest_sent = min(tokenized_sentences, key=len)\n",
        "        shortest_sent_len = len(shortest_sent)\n",
        "\n",
        "        return longest_sent_len, shortest_sent_len\n",
        "\n",
        "    def right_pad_sentences(self, max_sent_length):\n",
        "        max_len = round(max_sent_length * 0.50)  # Take 50% of the maximum sentence length to avoid sparsity\n",
        "        padded_sentences = []\n",
        "        # print(max_len)\n",
        "\n",
        "        for sentence in self.text:\n",
        "            sentence = sentence.strip()\n",
        "            sentence = sentence.split()\n",
        "\n",
        "            if len(sentence) > max_len:\n",
        "                a = sentence[:max_len]  # discard tokens longer than max_length\n",
        "                padded_sentences.append(a)\n",
        "\n",
        "            elif len(sentence) < max_len:\n",
        "                [sentence.append(\"0\") for i in\n",
        "                 range(max_len - len(sentence))]  # pad sentences with zeros smaller than max_length\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "            else:\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "        for pad_sent in padded_sentences:\n",
        "            list_sentences = ' '.join(pad_sent)\n",
        "            self.list_padded_sentences.append(list_sentences)\n",
        "\n",
        "        return self.list_padded_sentences\n",
        "\n",
        "    def merge_with(self, list2, list3):\n",
        "        merged = self.list_padded_sentences + list2 + list3\n",
        "        return merged\n",
        "\n",
        "\n",
        "class BagOfWords:\n",
        "\n",
        "    def __init__(self, all_padded_sentences, list_of_sentences):\n",
        "\n",
        "        # define punctuation and upper case alphabet\n",
        "        self.punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "        self.upper = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "        self.stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\",\n",
        "                          \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself',\n",
        "                          'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them',\n",
        "                          'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\",\n",
        "                          'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has',\n",
        "                          'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or',\n",
        "                          'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against',\n",
        "                          'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from',\n",
        "                          'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once',\n",
        "                          'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
        "                          'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than',\n",
        "                          'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd',\n",
        "                          'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn',\n",
        "                          \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\",\n",
        "                          'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\",\n",
        "                          'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won',\n",
        "                          \"won't\", 'wouldn', \"wouldn't\"]\n",
        "        self.vocab = self.generate_vocabulary(all_padded_sentences)  # Generate the vocabulary\n",
        "        # print(len(self.vocab))\n",
        "        self.dict_idx = self.indexing(self.vocab)  # Generate the indexing\n",
        "        self.word_count = self.count_dictionary(list_of_sentences)\n",
        "        self.N_sentences = len(list_of_sentences)\n",
        "\n",
        "    def lowercase_tokenize(self, padded_sentences):\n",
        "        lowercase = \"\"\n",
        "        for char in padded_sentences:\n",
        "            if char in self.upper:\n",
        "                k = ord(char)\n",
        "                l = k + 32\n",
        "                lowercase = lowercase + (chr(l))\n",
        "            elif char in self.punctuations:\n",
        "                continue\n",
        "            else:\n",
        "                lowercase = lowercase + char\n",
        "        lowercase = lowercase.strip()\n",
        "        tokenized = list(lowercase.split())\n",
        "        # print(tokenized)\n",
        "        return tokenized\n",
        "\n",
        "    def remove_stopwords(self, tokenized_sentences):\n",
        "        filtered_list = []\n",
        "        for token in tokenized_sentences:\n",
        "            if token in self.stopwords:\n",
        "                continue\n",
        "            else:\n",
        "                filtered_list.append(token)\n",
        "        return filtered_list\n",
        "\n",
        "    def generate_vocabulary(self, all_padded_sentences):\n",
        "        vocab = []\n",
        "        for sentence in all_padded_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            filtered_tokenized_sentence = self.remove_stopwords(tokenized_sentence)\n",
        "            for word in filtered_tokenized_sentence:  # append only unique words\n",
        "                if word not in vocab:\n",
        "                    vocab.append(word)\n",
        "        return vocab\n",
        "\n",
        "    def indexing(self, tokens):\n",
        "        # Index dictionary to assign an index to each word in vocabulary\n",
        "        index_word = {}\n",
        "        i = 0\n",
        "        for word in tokens:\n",
        "            index_word[word] = i\n",
        "            i += 1\n",
        "        return index_word\n",
        "\n",
        "    def count_dictionary(self, input_sentences):\n",
        "        word_count = {}\n",
        "        for word in self.vocab:\n",
        "            word_count[word] = 0.0\n",
        "            for sentence in input_sentences:\n",
        "                if word in sentence:\n",
        "                    word_count[word] += 1.0\n",
        "        return word_count\n",
        "\n",
        "    # Term Frequency\n",
        "    def termfreq(self, sentence, word):\n",
        "        number_of_sentences = float(len(sentence))\n",
        "        occurrence = float(len([token for token in sentence if token == word]))\n",
        "        return occurrence / number_of_sentences\n",
        "\n",
        "    def inverse_doc_freq(self, word):\n",
        "        try:\n",
        "            word_occurrence = self.word_count[word] + 1.0\n",
        "        except KeyError:\n",
        "            word_occurrence = 1.0\n",
        "        return np.log(self.N_sentences / word_occurrence)\n",
        "\n",
        "    def tf_idf(self, input_sentences):\n",
        "        row = 0\n",
        "        tf_idf_vec = np.zeros((self.N_sentences, (len(self.vocab))))\n",
        "\n",
        "        for sentence in input_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            filtered_tokenized_sentence = self.remove_stopwords(tokenized_sentence)\n",
        "            for word in filtered_tokenized_sentence:\n",
        "                tf = self.termfreq(sentence, word)\n",
        "                idf = self.inverse_doc_freq(word)\n",
        "\n",
        "                value = tf * idf\n",
        "                tf_idf_vec[row][self.dict_idx[word]] = value\n",
        "\n",
        "            row += 1\n",
        "\n",
        "        return tf_idf_vec"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXCuQpTO_f53"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT7n4bqFvsa9"
      },
      "source": [
        "### y data, one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDRL76A2vwK5"
      },
      "source": [
        "# from data_preprocessing.OneHotEncoding import *\n",
        "class OneHotEncoding:\n",
        "    def __init__(self, file_name):\n",
        "        self.mapping_dict = {}\n",
        "        #self.csv_file = pd.read_csv(file_name)\n",
        "        #self.labels = self.csv_file[\"label\"]\n",
        "\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.labels = []\n",
        "        for col in self.csv_file:\n",
        "            self.labels.append(col[\"label\"])\n",
        "\n",
        "        self.target_labels = []\n",
        "        for word in self.labels:\n",
        "            if word not in self.target_labels:\n",
        "                self.target_labels.append(word)\n",
        "\n",
        "        #self.target_labels = self.labels.unique()\n",
        "        self.labels_dict = {}\n",
        "        self.mapping()\n",
        "\n",
        "    def get_unique_labels(self):\n",
        "\n",
        "        return self.target_labels\n",
        "\n",
        "    def mapping(self):\n",
        "        ### map each emotion to an integer\n",
        "        one_hot_encoded = []\n",
        "        for label_idx in range(len(self.target_labels)):\n",
        "            self.mapping_dict[self.target_labels[label_idx]] = label_idx\n",
        "        #print(self.mapping_dict)\n",
        "\n",
        "        for c in self.target_labels:\n",
        "            arr = list(np.zeros(len(self.target_labels), dtype=int))\n",
        "            arr[self.mapping_dict[c]] = 1\n",
        "            one_hot_encoded.append(arr)\n",
        "\n",
        "        self.generate_dictionary(one_hot_encoded)\n",
        "\n",
        "        return one_hot_encoded\n",
        "\n",
        "    def generate_dictionary(self, one_hot_encoded):\n",
        "        self.labels_dict = dict(zip(self.target_labels, one_hot_encoded))  # universal dict\n",
        "\n",
        "    def one_hot_encoding(self, encoded_dict=None):\n",
        "        df_labels = []\n",
        "        if encoded_dict is None:\n",
        "            encoded_dict = self.labels_dict\n",
        "        for c in self.labels:\n",
        "            if c in encoded_dict.keys():\n",
        "                df_labels.append(encoded_dict[c])\n",
        "        return np.array(df_labels)\n",
        "\n",
        "    def get_encoded_dict(self):\n",
        "        return self.labels_dict"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgy4Z0ye_tE2"
      },
      "source": [
        ""
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loh79wNZwS_o"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ckMvLZvF2Q"
      },
      "source": [
        "class Linear():\n",
        "    def __init__(self, w, b):\n",
        "        self.w, self.b = w, b\n",
        "    def forward(self, x): \n",
        "        self.inp = x\n",
        "        self.out = self.inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        # set_trace()\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)\n",
        "\n",
        "\n",
        "class Relu():\n",
        "    def forward(self, x):\n",
        "        self.inp = x\n",
        "        self.out = x.clamp_min(0.) - 0.5\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g* (self.inp>0).float()\n",
        "\n",
        "class CrossEntropy():\n",
        "    def __call__(self, pred, y):\n",
        "        \n",
        "        self.yhat, self.y = pred, y\n",
        "        self.out = self.nll(self.log_softmax(pred), y)\n",
        "        \n",
        "        return self.out\n",
        "\n",
        "    #negative log likelihood\n",
        "    def nll(self, pred, y):\n",
        "        # print(pred.shape, y.shape)\n",
        "        return -pred[range(y.shape[0]), y.max(-1).indices].mean()\n",
        "\n",
        "    def log_softmax(self, x): return x - x.exp().sum(-1,keepdim=True).log()\n",
        "\n",
        "    def backward(self):\n",
        "        self.yhat.g = (self.yhat.exp()/(self.yhat.exp().sum(-1,keepdim=True))) - self.y\n",
        "\n",
        "class Mse():\n",
        "    def __call__(self, yhat, y):\n",
        "        # set_trace()\n",
        "        self.yhat, self.y = yhat, y\n",
        "        self.out = (yhat.squeeze(-1) - y).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.yhat.g = 2. * (self.yhat.squeeze() - self.y).unsqueeze(-1) / self.y.shape[0]\n",
        "\n",
        "class DummyModel():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.loss = CrossEntropy()\n",
        "        self.layers = [Linear(w1,b1), Relu(), Linear(w2, b2)]\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "\n",
        "        for layer in self.layers:\n",
        "            \n",
        "            x = layer.forward(x)\n",
        "        self.out = x\n",
        "        return self.loss(self.out, self.y)\n",
        "\n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for layer in reversed(self.layers):\n",
        "            # set_trace()\n",
        "            layer.backward()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4aEwhi9BjoL"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qdw_z2jsh02",
        "outputId": "48426618-af38-4990-c95a-fb8f44bce8d2"
      },
      "source": [
        "%cd /content/CLab21/"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CLab21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EWlD51R_68gY"
      },
      "source": [
        "# # in case you need debug\n",
        "# !pip install -q ipdb\n",
        "# from ipdb import set_trace"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqfMvzIJ--Qz"
      },
      "source": [
        "import numpy as np\n",
        "import csv, math\n",
        "from torch import tensor, float32, randn, no_grad"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi-LbQsQdngW"
      },
      "source": [
        "from pathlib import Path\n",
        "rpath = Path('/content/CLab21/data/emotions')"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Qh2Pe1sdFz"
      },
      "source": [
        "train_file = rpath/\"isear/isear-train-modified.csv\"\n",
        "val_file = rpath/\"isear/isear-val-modified.csv\"\n",
        "test_file = rpath/\"isear/isear-test-modified.csv\""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFXXMSNILzWK"
      },
      "source": [
        "- padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfnFBqGSLU7P"
      },
      "source": [
        "# %%timeit\n",
        "pml_train = PadMaxLength(train_file)\n",
        "pml_val = PadMaxLength(val_file)\n",
        "pml_test = PadMaxLength(test_file)\n",
        "\n",
        "max_sent, min_sent = pml_train.min_max_sentences()\n",
        "\n",
        "sentences_padded_train = pml_train.right_pad_sentences(max_sent)\n",
        "sentences_padded_val = pml_val.right_pad_sentences(max_sent)\n",
        "sentences_padded_test = pml_test.right_pad_sentences(max_sent)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkbLH5cL2x9"
      },
      "source": [
        "- vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBy365HgL1E4"
      },
      "source": [
        "# %timeit\n",
        "vocab_list = pml_train.merge_with(sentences_padded_val, sentences_padded_test)  # Vocab over all files\n",
        "\n",
        "bow_train = BagOfWords(vocab_list, sentences_padded_train)  # Sentences to create the vocabulary\n",
        "bow_val = BagOfWords(vocab_list, sentences_padded_val)\n",
        "bow_test = BagOfWords(vocab_list, sentences_padded_test)\n",
        "\n",
        "tf_idf_train = bow_train.tf_idf(sentences_padded_train)\n",
        "tf_idf_val = bow_val.tf_idf(sentences_padded_val)\n",
        "tf_idf_test = bow_test.tf_idf(sentences_padded_test)"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0PzRMeQMF_9"
      },
      "source": [
        "- y data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eXy6viABoQI"
      },
      "source": [
        "ohe_train = OneHotEncoding(train_file)\n",
        "ohe_val = OneHotEncoding(val_file)\n",
        "ohe_test = OneHotEncoding(test_file)\n",
        "\n",
        "y_train = ohe_train.one_hot_encoding()\n",
        "reference_dict = ohe_train.get_encoded_dict()\n",
        "\n",
        "y_val = ohe_val.one_hot_encoding(reference_dict)\n",
        "y_test = ohe_test.one_hot_encoding(reference_dict)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeZelBjOMJke"
      },
      "source": [
        "- torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE8tNCSTwkfm"
      },
      "source": [
        "train_x, train_y = tensor(tf_idf_train, dtype=float32), tensor(y_train)\n",
        "valid_x, valid_y = tensor(tf_idf_val, dtype=float32), tensor(y_val)"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU_2O7HYnsG9",
        "outputId": "8aeab3e1-0eb4-4de9-9ca3-c0f9990585a9"
      },
      "source": [
        "train_x.shape, valid_x.shape"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5344, 9226]), torch.Size([1148, 9226]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRwKN6JhCdEh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCGjqTKMohOR"
      },
      "source": [
        "train_x = train_x[:, :3000]\n",
        "valid_x = valid_x[:, :3000]"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZBx1tYwcke"
      },
      "source": [
        "#n: data size m: n_text_feature h: hidden node c: out node\n",
        "n, m, h, c = *train_x.shape, 100, train_y.shape[1]"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqSePVr9yNTq"
      },
      "source": [
        "w1 = randn(m, h) / math.sqrt(h)\n",
        "w2 = randn(h, c)\n",
        "b1 = randn(h)\n",
        "b2 = randn(c)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjpCwynUydkR"
      },
      "source": [
        "model = DummyModel(w1, b1, w2, b2)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZZVUjYc8187",
        "outputId": "d8b2fe31-b7d8-42da-f428-c9ac89afecc7"
      },
      "source": [
        "# loss before training\n",
        "model.forward(train_x[:32], train_y[:32])"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.9843)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ76bZPRwZcT"
      },
      "source": [
        "def train(epochs, bs, lr):\n",
        "    for e in range(epochs):\n",
        "        for bs_i in range((n-1)//bs + 1):\n",
        "            tot_w_mean, tot_w_std = 0, 0\n",
        "            str_idx, end_idx = bs_i*bs, (bs_i+1)*bs\n",
        "            x_batch, y_batch = train_x[str_idx:end_idx], train_y[str_idx:end_idx]\n",
        "            loss = model.forward(x_batch, y_batch)\n",
        "            model.backward()\n",
        "            \n",
        "            with no_grad():\n",
        "                for layer in model.layers:\n",
        "                    if hasattr(layer, 'w'): #if they have parameter attribute\n",
        "                        tot_w_mean+= layer.w.g.mean()\n",
        "                        tot_w_std += layer.w.g.std()\n",
        "                        layer.w -= layer.w.g * lr\n",
        "                        layer.b -= layer.b.g * lr\n",
        "                        layer.w.g.zero_() #initialize them to zero\n",
        "                        layer.b.g.zero_()\n",
        "            print(tot_w_mean/bs, tot_w_std/bs)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpPXcyAuyf5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c092f576-e937-4ce1-a326-1e2e14c5b3bd"
      },
      "source": [
        "train(1, 32, 1e-05)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(6.0360e-08) tensor(0.2030)\n",
            "tensor(1.3901e-08) tensor(0.1934)\n",
            "tensor(1.2655e-08) tensor(0.2158)\n",
            "tensor(4.5447e-08) tensor(0.1570)\n",
            "tensor(4.4887e-08) tensor(0.1985)\n",
            "tensor(5.7725e-08) tensor(0.2053)\n",
            "tensor(4.0773e-08) tensor(0.2031)\n",
            "tensor(3.4444e-08) tensor(0.2257)\n",
            "tensor(3.7779e-08) tensor(0.2097)\n",
            "tensor(2.0313e-08) tensor(0.1907)\n",
            "tensor(8.2982e-08) tensor(0.1894)\n",
            "tensor(1.8607e-08) tensor(0.2259)\n",
            "tensor(4.2639e-08) tensor(0.2060)\n",
            "tensor(1.1108e-08) tensor(0.1855)\n",
            "tensor(4.3884e-08) tensor(0.2111)\n",
            "tensor(5.2196e-09) tensor(0.1884)\n",
            "tensor(2.9704e-08) tensor(0.1547)\n",
            "tensor(1.9194e-08) tensor(0.1758)\n",
            "tensor(4.7443e-08) tensor(0.1590)\n",
            "tensor(1.4606e-08) tensor(0.1916)\n",
            "tensor(4.9878e-08) tensor(0.2177)\n",
            "tensor(1.1481e-08) tensor(0.2019)\n",
            "tensor(3.6657e-08) tensor(0.1923)\n",
            "tensor(4.9200e-08) tensor(0.1735)\n",
            "tensor(1.1435e-08) tensor(0.1655)\n",
            "tensor(8.8595e-09) tensor(0.1581)\n",
            "tensor(6.7336e-09) tensor(0.2016)\n",
            "tensor(1.4025e-08) tensor(0.1883)\n",
            "tensor(4.2124e-08) tensor(0.1683)\n",
            "tensor(4.8999e-08) tensor(0.2176)\n",
            "tensor(3.9857e-08) tensor(0.1758)\n",
            "tensor(1.9054e-08) tensor(0.1958)\n",
            "tensor(1.5662e-08) tensor(0.1752)\n",
            "tensor(2.1666e-08) tensor(0.1804)\n",
            "tensor(6.7758e-08) tensor(0.1798)\n",
            "tensor(9.9738e-08) tensor(0.1627)\n",
            "tensor(7.7217e-09) tensor(0.1651)\n",
            "tensor(3.3053e-08) tensor(0.1551)\n",
            "tensor(1.5385e-08) tensor(0.1909)\n",
            "tensor(1.5316e-08) tensor(0.1856)\n",
            "tensor(3.4508e-08) tensor(0.1852)\n",
            "tensor(2.0325e-08) tensor(0.1983)\n",
            "tensor(8.9000e-09) tensor(0.1746)\n",
            "tensor(3.4573e-08) tensor(0.1803)\n",
            "tensor(1.0572e-09) tensor(0.1840)\n",
            "tensor(7.1726e-08) tensor(0.1888)\n",
            "tensor(1.4579e-08) tensor(0.1667)\n",
            "tensor(4.9687e-08) tensor(0.1468)\n",
            "tensor(7.9504e-08) tensor(0.1650)\n",
            "tensor(1.7890e-08) tensor(0.1738)\n",
            "tensor(1.4760e-08) tensor(0.1783)\n",
            "tensor(3.3019e-08) tensor(0.1729)\n",
            "tensor(2.2663e-08) tensor(0.1785)\n",
            "tensor(6.3423e-08) tensor(0.1808)\n",
            "tensor(1.7808e-08) tensor(0.1767)\n",
            "tensor(6.2594e-08) tensor(0.1972)\n",
            "tensor(1.6394e-08) tensor(0.1678)\n",
            "tensor(1.9886e-08) tensor(0.1964)\n",
            "tensor(6.4487e-08) tensor(0.1537)\n",
            "tensor(3.2819e-08) tensor(0.1543)\n",
            "tensor(2.7287e-08) tensor(0.1783)\n",
            "tensor(5.2800e-08) tensor(0.1419)\n",
            "tensor(3.2958e-08) tensor(0.1489)\n",
            "tensor(7.3671e-09) tensor(0.1587)\n",
            "tensor(9.5217e-09) tensor(0.1442)\n",
            "tensor(3.9564e-08) tensor(0.1724)\n",
            "tensor(4.2099e-08) tensor(0.1900)\n",
            "tensor(4.5920e-08) tensor(0.1512)\n",
            "tensor(3.4678e-08) tensor(0.1658)\n",
            "tensor(3.4527e-08) tensor(0.1415)\n",
            "tensor(3.4241e-08) tensor(0.1325)\n",
            "tensor(7.5335e-08) tensor(0.1867)\n",
            "tensor(1.3369e-08) tensor(0.1800)\n",
            "tensor(1.7949e-08) tensor(0.1532)\n",
            "tensor(6.0620e-08) tensor(0.1817)\n",
            "tensor(5.2822e-08) tensor(0.1479)\n",
            "tensor(1.0287e-08) tensor(0.1220)\n",
            "tensor(-9.8272e-09) tensor(0.1415)\n",
            "tensor(1.6356e-08) tensor(0.1630)\n",
            "tensor(5.2038e-08) tensor(0.1438)\n",
            "tensor(1.1980e-08) tensor(0.1400)\n",
            "tensor(2.2142e-08) tensor(0.1741)\n",
            "tensor(1.3640e-08) tensor(0.1810)\n",
            "tensor(2.0189e-08) tensor(0.1776)\n",
            "tensor(7.9554e-08) tensor(0.1513)\n",
            "tensor(5.5839e-08) tensor(0.1459)\n",
            "tensor(1.4126e-08) tensor(0.1104)\n",
            "tensor(1.6135e-08) tensor(0.1460)\n",
            "tensor(1.5724e-08) tensor(0.1752)\n",
            "tensor(4.9660e-08) tensor(0.1499)\n",
            "tensor(4.9574e-08) tensor(0.1665)\n",
            "tensor(1.4985e-08) tensor(0.1318)\n",
            "tensor(5.8626e-08) tensor(0.1718)\n",
            "tensor(-3.5746e-09) tensor(0.1484)\n",
            "tensor(3.2114e-08) tensor(0.1668)\n",
            "tensor(1.2382e-08) tensor(0.1600)\n",
            "tensor(1.6146e-08) tensor(0.1454)\n",
            "tensor(9.4637e-09) tensor(0.1204)\n",
            "tensor(9.7176e-09) tensor(0.1491)\n",
            "tensor(1.5387e-08) tensor(0.1565)\n",
            "tensor(5.6185e-08) tensor(0.1369)\n",
            "tensor(6.8832e-08) tensor(0.1225)\n",
            "tensor(2.7994e-08) tensor(0.1584)\n",
            "tensor(6.3234e-09) tensor(0.1297)\n",
            "tensor(2.5018e-08) tensor(0.1155)\n",
            "tensor(1.8896e-08) tensor(0.1073)\n",
            "tensor(1.3893e-08) tensor(0.1502)\n",
            "tensor(3.3058e-08) tensor(0.1744)\n",
            "tensor(1.1989e-08) tensor(0.1284)\n",
            "tensor(2.3188e-08) tensor(0.1491)\n",
            "tensor(1.2859e-08) tensor(0.1622)\n",
            "tensor(1.7546e-08) tensor(0.1335)\n",
            "tensor(1.4886e-08) tensor(0.1564)\n",
            "tensor(3.7272e-09) tensor(0.1364)\n",
            "tensor(3.3749e-08) tensor(0.1525)\n",
            "tensor(5.0342e-08) tensor(0.1484)\n",
            "tensor(2.0326e-08) tensor(0.1373)\n",
            "tensor(3.9496e-09) tensor(0.1105)\n",
            "tensor(2.9878e-08) tensor(0.1223)\n",
            "tensor(-8.8018e-09) tensor(0.1219)\n",
            "tensor(-1.0657e-09) tensor(0.1449)\n",
            "tensor(-2.2627e-09) tensor(0.0889)\n",
            "tensor(3.7218e-09) tensor(0.1362)\n",
            "tensor(-4.3977e-09) tensor(0.1063)\n",
            "tensor(1.5941e-08) tensor(0.1269)\n",
            "tensor(1.6623e-08) tensor(0.1275)\n",
            "tensor(1.0036e-08) tensor(0.1257)\n",
            "tensor(5.7894e-08) tensor(0.1112)\n",
            "tensor(4.8898e-08) tensor(0.1458)\n",
            "tensor(3.7762e-08) tensor(0.1150)\n",
            "tensor(9.7359e-09) tensor(0.1547)\n",
            "tensor(1.2111e-08) tensor(0.1215)\n",
            "tensor(8.4770e-09) tensor(0.1022)\n",
            "tensor(7.4851e-09) tensor(0.0965)\n",
            "tensor(1.6428e-08) tensor(0.1441)\n",
            "tensor(7.7502e-09) tensor(0.1150)\n",
            "tensor(8.3720e-08) tensor(0.1489)\n",
            "tensor(6.7088e-08) tensor(0.1520)\n",
            "tensor(2.5492e-08) tensor(0.1219)\n",
            "tensor(1.0135e-08) tensor(0.1170)\n",
            "tensor(4.2111e-08) tensor(0.1231)\n",
            "tensor(7.3524e-08) tensor(0.1530)\n",
            "tensor(6.6085e-08) tensor(0.1343)\n",
            "tensor(8.6407e-09) tensor(0.1232)\n",
            "tensor(1.9547e-08) tensor(0.1498)\n",
            "tensor(2.7949e-08) tensor(0.1503)\n",
            "tensor(2.2207e-08) tensor(0.1553)\n",
            "tensor(1.3784e-08) tensor(0.1328)\n",
            "tensor(1.7994e-08) tensor(0.1675)\n",
            "tensor(1.7687e-08) tensor(0.1617)\n",
            "tensor(1.6144e-08) tensor(0.1519)\n",
            "tensor(3.5425e-08) tensor(0.1354)\n",
            "tensor(6.7388e-08) tensor(0.1377)\n",
            "tensor(1.7289e-08) tensor(0.1313)\n",
            "tensor(1.2313e-08) tensor(0.1479)\n",
            "tensor(3.2357e-08) tensor(0.1371)\n",
            "tensor(3.2561e-08) tensor(0.1196)\n",
            "tensor(8.4372e-08) tensor(0.1271)\n",
            "tensor(1.6312e-08) tensor(0.1528)\n",
            "tensor(-5.3393e-09) tensor(0.1488)\n",
            "tensor(1.9792e-08) tensor(0.1511)\n",
            "tensor(1.5453e-08) tensor(0.1413)\n",
            "tensor(-7.7525e-10) tensor(0.1185)\n",
            "tensor(2.8492e-08) tensor(0.1067)\n",
            "tensor(3.9229e-08) tensor(0.1427)\n",
            "tensor(6.0043e-08) tensor(0.1292)\n",
            "tensor(9.4634e-09) tensor(0.1189)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-psGH5eN6Vg0",
        "outputId": "d6d639fe-3a30-49b4-c6aa-42a4988ed4df"
      },
      "source": [
        "# loss after training\n",
        "model.forward(train_x[:32], train_y[:32])"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(4.6360)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGakSGQqDc4p"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye023wz2fv0Q",
        "outputId": "f30888b6-db39-4706-9866-06ba5fcf925b"
      },
      "source": [
        "model.forward(valid_x, valid_y)"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.2979)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4awxiCLpgs0"
      },
      "source": [
        "pred = model.loss.log_softmax(model.loss.yhat)"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk6O6M2YDeE_"
      },
      "source": [
        "class Fscore():\n",
        "    def __init__(self, inp, trg):\n",
        "        self.inp, self.trg = inp.max(-1).indices, trg.max(-1).indices\n",
        "        self.c = inp.shape[1]\n",
        "    def __call__(self, alpha = 0.5):\n",
        "        self.precision()\n",
        "        self.recall()\n",
        "        f1 = map(\n",
        "            self.fscore, self.tot_pre, self.tot_rec\n",
        "            )\n",
        "        return self.tot_pre, self.tot_rec, list(f1)\n",
        "    def fscore(self, x, y):\n",
        "        return (2*x*y)/(x+y)\n",
        "    \n",
        "    def precision(self):\n",
        "        self.tot_pre= []\n",
        "        for i in range(self.c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.inp ==i\n",
        "            if not sum(denom)==0: self.tot_pre += [sum(numer) / sum(denom)]\n",
        "            else: self.tot_pre += [0.]\n",
        "\n",
        "    def recall(self):\n",
        "        self.tot_rec= []\n",
        "        for i in range(self.c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.trg ==i\n",
        "            if not sum(denom)==0: self.tot_rec += [sum(numer) / sum(denom)]\n",
        "            else: self.tot_rec += [0.]"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJUJxDaasgRu"
      },
      "source": [
        "measure = Fscore(pred, valid_y)\n",
        "p, r, f = measure()"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8fdhJEldm30",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5c36d51-f7e0-4974-d41c-208e37db573a"
      },
      "source": [
        "p, r, f"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([0.0, 0.0, tensor(0.1455), 0.0, 0.0, 0.0, 0.0],\n",
              " [tensor(1.1060),\n",
              "  tensor(0.9766),\n",
              "  tensor(1.),\n",
              "  tensor(1.0503),\n",
              "  tensor(1.0121),\n",
              "  tensor(1.0438),\n",
              "  tensor(0.9543)],\n",
              " [tensor(0.),\n",
              "  tensor(0.),\n",
              "  tensor(0.2540),\n",
              "  tensor(0.),\n",
              "  tensor(0.),\n",
              "  tensor(0.),\n",
              "  tensor(0.)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqVJsTsbQlW"
      },
      "source": [
        ""
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRaBDwrVmNlT"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-k8n2Iw4mOfb"
      },
      "source": [
        "## [sklearn.metrics.classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HxFGnf5mYUH",
        "outputId": "18b4e4d8-dac4-4706-be2a-c639f96ec80d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "trg_names = list(reference_dict.keys())\n",
        "print(classification_report(y_true = measure.trg, y_pred = measure.inp, target_names=trg_names))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         joy       0.00      0.00      0.00       151\n",
            "        fear       0.00      0.00      0.00       171\n",
            "       shame       0.15      1.00      0.25       167\n",
            "     disgust       0.00      0.00      0.00       159\n",
            "       guilt       0.00      0.00      0.00       165\n",
            "       anger       0.00      0.00      0.00       160\n",
            "     sadness       0.00      0.00      0.00       175\n",
            "\n",
            "    accuracy                           0.15      1148\n",
            "   macro avg       0.02      0.14      0.04      1148\n",
            "weighted avg       0.02      0.15      0.04      1148\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}