{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_2021_05_12_merge_code.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "zwxJN-alkO9V",
        "qAr2ogy3sLeW",
        "gRWgXS_wvonM",
        "oT7n4bqFvsa9",
        "Loh79wNZwS_o",
        "i4aEwhi9BjoL"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SpellOnYou/CLab21/blob/main/midterm/2021_05_20_merge_code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwxJN-alkO9V"
      },
      "source": [
        "## Enviroment setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7k232czaeCGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7c8e77a-af20-4cd0-93a2-d1e369cf299d"
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "# repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone https://{0}:{1}@github.com/{0}/CLab21.git'.format(user, password)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User name: SpellOnYou\n",
            "Password: ··········\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAr2ogy3sLeW"
      },
      "source": [
        "## Pre-processing(text representation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9HpXhzDALSn"
      },
      "source": [
        "Comment\n",
        "\n",
        "1. Generally don't need to use external library to read csv. open() function will work.\n",
        "2. Now we read one file twice(1. for sentence padding, 2. one-hot encoding) --> not efficient way to use computation resource :) should consider reconstructuring data loading process.\n",
        "3. Didn't investigate the whole algorithm. But BOW took much time compared to its data size. Need to be checked."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRWgXS_wvonM"
      },
      "source": [
        "### x data, tf-idf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woGbW17CslSY"
      },
      "source": [
        "class PadMaxLength:\n",
        "\n",
        "    def __init__(self, file_name):\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.list_padded_sentences = []\n",
        "        self.text = []\n",
        "        for col in self.csv_file:\n",
        "            self.text.append(col[\"text\"])\n",
        "\n",
        "    def min_max_sentences(self):\n",
        "        tokenized_sentences = []\n",
        "        # split each sentence into words\n",
        "        for sentence in self.text:\n",
        "            tokens = sentence.split()\n",
        "            tokenized_sentences.append(tokens)\n",
        "        # get longest sentence and its length\n",
        "        longest_sent = max(tokenized_sentences, key=len)\n",
        "        longest_sent_len = len(longest_sent)\n",
        "\n",
        "        # get shortest word and its length\n",
        "        shortest_sent = min(tokenized_sentences, key=len)\n",
        "        shortest_sent_len = len(shortest_sent)\n",
        "\n",
        "        return longest_sent_len, shortest_sent_len\n",
        "\n",
        "    def right_pad_sentences(self, max_sent_length):\n",
        "        max_len = round(max_sent_length * 0.50)  # Take 50% of the maximum sentence length to avoid sparsity\n",
        "        padded_sentences = []\n",
        "        # print(max_len)\n",
        "\n",
        "        for sentence in self.text:\n",
        "            sentence = sentence.strip()\n",
        "            sentence = sentence.split()\n",
        "\n",
        "            if len(sentence) > max_len:\n",
        "                a = sentence[:max_len]  # discard tokens longer than max_length\n",
        "                padded_sentences.append(a)\n",
        "\n",
        "            elif len(sentence) < max_len:\n",
        "                [sentence.append(\"0\") for i in\n",
        "                 range(max_len - len(sentence))]  # pad sentences with zeros smaller than max_length\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "            else:\n",
        "                padded_sentences.append(sentence)\n",
        "\n",
        "        for pad_sent in padded_sentences:\n",
        "            list_sentences = ' '.join(pad_sent)\n",
        "            self.list_padded_sentences.append(list_sentences)\n",
        "\n",
        "        return self.list_padded_sentences\n",
        "\n",
        "    def merge_with(self, list2, list3):\n",
        "        merged = self.list_padded_sentences + list2 + list3\n",
        "        return merged"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS7wfoe__X-_"
      },
      "source": [
        "\n",
        "class BagOfWords:\n",
        "\n",
        "    def __init__(self, all_padded_sentences, list_of_sentences):\n",
        "\n",
        "        # define punctuation and upper case alphabet\n",
        "        self.punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "        self.upper = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'\n",
        "        self.vocab = self.generate_vocabulary(all_padded_sentences)  # Generate the vocabulary\n",
        "        #print(len(self.vocab))\n",
        "        self.dict_idx = self.indexing(self.vocab)  # Generate the indexing\n",
        "        self.word_count = self.count_dictionary(list_of_sentences)\n",
        "        self.N_sentences = len(list_of_sentences)\n",
        "\n",
        "    def lowercase_tokenize(self, padded_sentences):\n",
        "        lowercase = \"\"\n",
        "        for char in padded_sentences:\n",
        "            if char in self.upper:\n",
        "                k = ord(char)\n",
        "                l = k + 32\n",
        "                lowercase = lowercase + (chr(l))\n",
        "            elif char in self.punctuations:\n",
        "                continue\n",
        "            else:\n",
        "                lowercase = lowercase + char\n",
        "        lowercase = lowercase.strip()\n",
        "        tokenized = list(lowercase.split())\n",
        "        return tokenized\n",
        "\n",
        "    def generate_vocabulary(self, all_padded_sentences):\n",
        "        vocab = []\n",
        "        for sentence in all_padded_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            for word in tokenized_sentence:  # append only unique words\n",
        "                if word not in vocab:\n",
        "                    vocab.append(word)\n",
        "        return vocab\n",
        "\n",
        "    def indexing(self, tokens):\n",
        "        # Index dictionary to assign an index to each word in vocabulary\n",
        "        index_word = {}\n",
        "        i = 0\n",
        "        for word in tokens:\n",
        "            index_word[word] = i\n",
        "            i += 1\n",
        "        return index_word\n",
        "\n",
        "    def count_dictionary(self, input_sentences):\n",
        "        word_count = {}\n",
        "        for word in self.vocab:\n",
        "            word_count[word] = 0.0\n",
        "            for sentence in input_sentences:\n",
        "                if word in sentence:\n",
        "                    word_count[word] += 1.0\n",
        "        return word_count\n",
        "\n",
        "    # Term Frequency\n",
        "    def termfreq(self, sentence, word):\n",
        "        number_of_sentences = float(len(sentence))\n",
        "        occurrence = float(len([token for token in sentence if token == word]))\n",
        "        return occurrence / number_of_sentences\n",
        "\n",
        "    def inverse_doc_freq(self, word):\n",
        "        try:\n",
        "            word_occurrence = self.word_count[word] + 1.0\n",
        "        except KeyError:\n",
        "            word_occurrence = 1.0\n",
        "        return np.log(self.N_sentences / word_occurrence)\n",
        "\n",
        "    def tf_idf(self, input_sentences):\n",
        "        row = 0\n",
        "        tf_idf_vec = np.zeros((self.N_sentences, (len(self.vocab))))\n",
        "\n",
        "        for sentence in input_sentences:\n",
        "            tokenized_sentence = self.lowercase_tokenize(sentence)\n",
        "            for word in tokenized_sentence:\n",
        "                tf = self.termfreq(sentence, word)\n",
        "                idf = self.inverse_doc_freq(word)\n",
        "\n",
        "                value = tf * idf\n",
        "                tf_idf_vec[row][self.dict_idx[word]] = value\n",
        "\n",
        "            row += 1\n",
        "\n",
        "        return tf_idf_vec\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXCuQpTO_f53"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT7n4bqFvsa9"
      },
      "source": [
        "### y data, one-hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDRL76A2vwK5"
      },
      "source": [
        "# from data_preprocessing.OneHotEncoding import *\n",
        "class OneHotEncoding:\n",
        "    def __init__(self, file_name):\n",
        "        self.mapping_dict = {}\n",
        "        #self.csv_file = pd.read_csv(file_name)\n",
        "        #self.labels = self.csv_file[\"label\"]\n",
        "\n",
        "        self.file = open(file_name)\n",
        "        self.csv_file = csv.DictReader(self.file)\n",
        "        self.labels = []\n",
        "        for col in self.csv_file:\n",
        "            self.labels.append(col[\"label\"])\n",
        "\n",
        "        self.target_labels = []\n",
        "        for word in self.labels:\n",
        "            if word not in self.target_labels:\n",
        "                self.target_labels.append(word)\n",
        "\n",
        "        #self.target_labels = self.labels.unique()\n",
        "        self.labels_dict = {}\n",
        "        self.mapping()\n",
        "\n",
        "    def get_unique_labels(self):\n",
        "\n",
        "        return self.target_labels\n",
        "\n",
        "    def mapping(self):\n",
        "        ### map each emotion to an integer\n",
        "        one_hot_encoded = []\n",
        "        for label_idx in range(len(self.target_labels)):\n",
        "            self.mapping_dict[self.target_labels[label_idx]] = label_idx\n",
        "        #print(self.mapping_dict)\n",
        "\n",
        "        for c in self.target_labels:\n",
        "            arr = list(np.zeros(len(self.target_labels), dtype=int))\n",
        "            arr[self.mapping_dict[c]] = 1\n",
        "            one_hot_encoded.append(arr)\n",
        "\n",
        "        self.generate_dictionary(one_hot_encoded)\n",
        "\n",
        "        return one_hot_encoded\n",
        "\n",
        "    def generate_dictionary(self, one_hot_encoded):\n",
        "        self.labels_dict = dict(zip(self.target_labels, one_hot_encoded))  # universal dict\n",
        "\n",
        "    def one_hot_encoding(self, encoded_dict=None):\n",
        "        df_labels = []\n",
        "        if encoded_dict is None:\n",
        "            encoded_dict = self.labels_dict\n",
        "        for c in self.labels:\n",
        "            if c in encoded_dict.keys():\n",
        "                df_labels.append(encoded_dict[c])\n",
        "        return np.array(df_labels)\n",
        "\n",
        "    def get_encoded_dict(self):\n",
        "        return self.labels_dict"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pgy4Z0ye_tE2"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loh79wNZwS_o"
      },
      "source": [
        "## Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6ckMvLZvF2Q"
      },
      "source": [
        "class Linear():\n",
        "    def __init__(self, w, b):\n",
        "        self.w, self.b = w, b\n",
        "    def forward(self, x): \n",
        "        self.inp = x\n",
        "        self.out = self.inp@self.w + self.b\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        # set_trace()\n",
        "        self.inp.g = self.out.g @ self.w.t()\n",
        "        self.w.g = (self.inp.unsqueeze(-1) * self.out.g.unsqueeze(1)).sum(0)\n",
        "        self.b.g = self.out.g.sum(0)\n",
        "\n",
        "\n",
        "class Relu():\n",
        "    def forward(self, x):\n",
        "        self.inp = x\n",
        "        self.out = x.clamp_min(0.) - 0.5\n",
        "        return self.out\n",
        "\n",
        "    def backward(self):\n",
        "        self.inp.g = self.out.g* (self.inp>0).float()\n",
        "\n",
        "class CrossEntropy():\n",
        "    def __call__(self, pred, y):\n",
        "        \n",
        "        self.yhat, self.y = pred, y\n",
        "        self.out = self.nll(self.log_softmax(pred), y)\n",
        "        \n",
        "        return self.out\n",
        "\n",
        "    #negative log likelihood\n",
        "    def nll(self, pred, y):\n",
        "        # print(pred.shape, y.shape)\n",
        "        return -pred[range(y.shape[0]), y.max(-1).indices].mean()\n",
        "\n",
        "    def log_softmax(self, x): return x - x.exp().sum(-1,keepdim=True).log()\n",
        "\n",
        "    def backward(self):\n",
        "        self.yhat.g = (self.yhat.exp()/(self.yhat.exp().sum(-1,keepdim=True))) - self.y\n",
        "\n",
        "class Mse():\n",
        "    def __call__(self, yhat, y):\n",
        "        # set_trace()\n",
        "        self.yhat, self.y = yhat, y\n",
        "        self.out = (yhat.squeeze(-1) - y).pow(2).mean()\n",
        "        return self.out\n",
        "    \n",
        "    def backward(self):\n",
        "        self.yhat.g = 2. * (self.yhat.squeeze() - self.y).unsqueeze(-1) / self.y.shape[0]\n",
        "\n",
        "class DummyModel():\n",
        "    def __init__(self, w1, b1, w2, b2):\n",
        "        self.loss = CrossEntropy()\n",
        "        self.layers = [Linear(w1,b1), Relu(), Linear(w2, b2)]\n",
        "    \n",
        "    def forward(self, x, y):\n",
        "        self.x, self.y = x, y\n",
        "\n",
        "        for layer in self.layers:\n",
        "            \n",
        "            x = layer.forward(x)\n",
        "        self.out = x\n",
        "        return self.loss(self.out, self.y)\n",
        "\n",
        "    def backward(self):\n",
        "        self.loss.backward()\n",
        "        for layer in reversed(self.layers):\n",
        "            # set_trace()\n",
        "            layer.backward()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4aEwhi9BjoL"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-qdw_z2jsh02",
        "outputId": "2eaf60ce-d1ea-405f-f4c3-6f1e5c94f8ea"
      },
      "source": [
        "%cd /content/CLab21/"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/CLab21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "id": "EWlD51R_68gY"
      },
      "source": [
        "# # in case you need debug\n",
        "# !pip install -q ipdb\n",
        "# from ipdb import set_trace"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqfMvzIJ--Qz"
      },
      "source": [
        "import numpy as np\n",
        "import csv, math\n",
        "from torch import tensor, float32, randn, no_grad"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi-LbQsQdngW"
      },
      "source": [
        "from pathlib import Path\n",
        "rpath = Path('/content/CLab21/data/emotions')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5Qh2Pe1sdFz"
      },
      "source": [
        "train_file = rpath/\"isear/isear-train-modified.csv\"\n",
        "val_file = rpath/\"isear/isear-val-modified.csv\"\n",
        "test_file = rpath/\"isear/isear-test-modified.csv\""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFXXMSNILzWK"
      },
      "source": [
        "- padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfnFBqGSLU7P"
      },
      "source": [
        "# %%timeit\n",
        "pml_train = PadMaxLength(train_file)\n",
        "pml_val = PadMaxLength(val_file)\n",
        "pml_test = PadMaxLength(test_file)\n",
        "\n",
        "max_sent, min_sent = pml_train.min_max_sentences()\n",
        "\n",
        "sentences_padded_train = pml_train.right_pad_sentences(max_sent)\n",
        "sentences_padded_val = pml_val.right_pad_sentences(max_sent)\n",
        "sentences_padded_test = pml_test.right_pad_sentences(max_sent)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LYkbLH5cL2x9"
      },
      "source": [
        "- vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBy365HgL1E4"
      },
      "source": [
        "# %timeit\n",
        "vocab_list = pml_train.merge_with(sentences_padded_val, sentences_padded_test)  # Vocab over all files\n",
        "\n",
        "bow_train = BagOfWords(vocab_list, sentences_padded_train)  # Sentences to create the vocabulary\n",
        "bow_val = BagOfWords(vocab_list, sentences_padded_val)\n",
        "bow_test = BagOfWords(vocab_list, sentences_padded_test)\n",
        "\n",
        "tf_idf_train = bow_train.tf_idf(sentences_padded_train)\n",
        "tf_idf_val = bow_val.tf_idf(sentences_padded_val)\n",
        "tf_idf_test = bow_test.tf_idf(sentences_padded_test)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0PzRMeQMF_9"
      },
      "source": [
        "- y data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eXy6viABoQI"
      },
      "source": [
        "ohe_train = OneHotEncoding(train_file)\n",
        "ohe_val = OneHotEncoding(val_file)\n",
        "ohe_test = OneHotEncoding(test_file)\n",
        "\n",
        "y_train = ohe_train.one_hot_encoding()\n",
        "reference_dict = ohe_train.get_encoded_dict()\n",
        "\n",
        "y_val = ohe_val.one_hot_encoding(reference_dict)\n",
        "y_test = ohe_test.one_hot_encoding(reference_dict)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeZelBjOMJke"
      },
      "source": [
        "- torch tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wE8tNCSTwkfm"
      },
      "source": [
        "train_x, train_y = tensor(tf_idf_train, dtype=float32), tensor(y_train)\n",
        "valid_x, valid_y = tensor(tf_idf_val, dtype=float32), tensor(y_val)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU_2O7HYnsG9",
        "outputId": "de0861c0-54c7-4000-fbec-40307493d9c3"
      },
      "source": [
        "train_x.shape, valid_x.shape"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([5344, 9355]), torch.Size([1148, 9355]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRwKN6JhCdEh"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCGjqTKMohOR"
      },
      "source": [
        "train_x = train_x[:, :3000]\n",
        "valid_x = valid_x[:, :3000]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnZBx1tYwcke"
      },
      "source": [
        "#n: data size m: n_text_feature h: hidden node c: out node\n",
        "n, m, h, c = *train_x.shape, 100, train_y.shape[1]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqSePVr9yNTq"
      },
      "source": [
        "w1 = randn(m, h) / math.sqrt(h)\n",
        "w2 = randn(h, c)\n",
        "b1 = randn(h)\n",
        "b2 = randn(c)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zjpCwynUydkR"
      },
      "source": [
        "model = DummyModel(w1, b1, w2, b2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZZVUjYc8187",
        "outputId": "530fb87a-88eb-4d6c-fdab-9411c5165673"
      },
      "source": [
        "# loss before training\n",
        "model.forward(train_x[:32], train_y[:32])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.5617)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZ76bZPRwZcT"
      },
      "source": [
        "def train(epochs, bs, lr):\n",
        "    for e in range(epochs):\n",
        "        for bs_i in range((n-1)//bs + 1):\n",
        "            tot_w_mean, tot_w_std = 0, 0\n",
        "            str_idx, end_idx = bs_i*bs, (bs_i+1)*bs\n",
        "            x_batch, y_batch = train_x[str_idx:end_idx], train_y[str_idx:end_idx]\n",
        "            loss = model.forward(x_batch, y_batch)\n",
        "            model.backward()\n",
        "            \n",
        "            with no_grad():\n",
        "                for layer in model.layers:\n",
        "                    if hasattr(layer, 'w'): #if they have parameter attribute\n",
        "                        tot_w_mean+= layer.w.g.mean()\n",
        "                        tot_w_std += layer.w.g.std()\n",
        "                        layer.w -= layer.w.g * lr\n",
        "                        layer.b -= layer.b.g * lr\n",
        "                        layer.w.g.zero_() #initialize them to zero\n",
        "                        layer.b.g.zero_()\n",
        "            print(tot_w_mean/bs, tot_w_std/bs)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpPXcyAuyf5g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a04767d-9a0d-4a91-e7b6-5948b8963df2"
      },
      "source": [
        "train(1, 32, 1e-05)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(1.8843e-08) tensor(0.1313)\n",
            "tensor(1.4983e-08) tensor(0.1266)\n",
            "tensor(1.6590e-08) tensor(0.1576)\n",
            "tensor(2.3049e-09) tensor(0.1164)\n",
            "tensor(1.6264e-08) tensor(0.1384)\n",
            "tensor(1.5317e-08) tensor(0.1368)\n",
            "tensor(6.3726e-09) tensor(0.1356)\n",
            "tensor(2.1700e-08) tensor(0.1630)\n",
            "tensor(1.8645e-08) tensor(0.1328)\n",
            "tensor(7.0525e-09) tensor(0.1229)\n",
            "tensor(2.6134e-08) tensor(0.1240)\n",
            "tensor(1.4206e-08) tensor(0.1623)\n",
            "tensor(1.6325e-08) tensor(0.1243)\n",
            "tensor(1.6598e-08) tensor(0.1365)\n",
            "tensor(1.7018e-08) tensor(0.1255)\n",
            "tensor(3.5936e-08) tensor(0.1269)\n",
            "tensor(1.1432e-08) tensor(0.1167)\n",
            "tensor(1.0421e-08) tensor(0.1241)\n",
            "tensor(7.8539e-09) tensor(0.1193)\n",
            "tensor(1.4254e-08) tensor(0.1521)\n",
            "tensor(2.4096e-08) tensor(0.1523)\n",
            "tensor(1.9778e-08) tensor(0.1554)\n",
            "tensor(1.2330e-08) tensor(0.1439)\n",
            "tensor(1.1880e-08) tensor(0.1122)\n",
            "tensor(7.4897e-09) tensor(0.1178)\n",
            "tensor(1.5526e-08) tensor(0.1253)\n",
            "tensor(1.3939e-08) tensor(0.1582)\n",
            "tensor(1.4587e-08) tensor(0.1538)\n",
            "tensor(1.3547e-08) tensor(0.1242)\n",
            "tensor(1.7939e-08) tensor(0.1634)\n",
            "tensor(7.4259e-09) tensor(0.1317)\n",
            "tensor(2.1873e-08) tensor(0.1542)\n",
            "tensor(2.3232e-08) tensor(0.1202)\n",
            "tensor(1.1862e-08) tensor(0.1422)\n",
            "tensor(1.7144e-08) tensor(0.1193)\n",
            "tensor(2.4359e-08) tensor(0.1415)\n",
            "tensor(1.6981e-08) tensor(0.1241)\n",
            "tensor(5.2751e-09) tensor(0.1146)\n",
            "tensor(1.4228e-08) tensor(0.1337)\n",
            "tensor(1.9983e-08) tensor(0.1256)\n",
            "tensor(2.0204e-08) tensor(0.1235)\n",
            "tensor(9.7263e-09) tensor(0.1571)\n",
            "tensor(7.9361e-09) tensor(0.1471)\n",
            "tensor(1.6973e-08) tensor(0.1478)\n",
            "tensor(1.8745e-08) tensor(0.1412)\n",
            "tensor(1.0330e-08) tensor(0.1491)\n",
            "tensor(-6.7389e-09) tensor(0.1264)\n",
            "tensor(9.1966e-09) tensor(0.1275)\n",
            "tensor(2.1814e-08) tensor(0.1164)\n",
            "tensor(1.4173e-08) tensor(0.1266)\n",
            "tensor(1.2791e-08) tensor(0.1523)\n",
            "tensor(1.3097e-08) tensor(0.1239)\n",
            "tensor(1.1128e-08) tensor(0.1257)\n",
            "tensor(2.1974e-08) tensor(0.1673)\n",
            "tensor(1.0077e-08) tensor(0.1275)\n",
            "tensor(1.0142e-08) tensor(0.1432)\n",
            "tensor(4.2269e-09) tensor(0.1379)\n",
            "tensor(2.0234e-08) tensor(0.1517)\n",
            "tensor(1.1330e-08) tensor(0.1250)\n",
            "tensor(1.0690e-08) tensor(0.1258)\n",
            "tensor(1.9435e-08) tensor(0.1347)\n",
            "tensor(1.5792e-08) tensor(0.1155)\n",
            "tensor(6.4830e-09) tensor(0.1239)\n",
            "tensor(1.6797e-08) tensor(0.1376)\n",
            "tensor(1.2290e-08) tensor(0.1241)\n",
            "tensor(1.1656e-08) tensor(0.1333)\n",
            "tensor(2.1315e-08) tensor(0.1297)\n",
            "tensor(8.1820e-09) tensor(0.1279)\n",
            "tensor(5.4197e-09) tensor(0.1369)\n",
            "tensor(1.6727e-08) tensor(0.1334)\n",
            "tensor(2.2628e-08) tensor(0.1108)\n",
            "tensor(1.6506e-08) tensor(0.1646)\n",
            "tensor(2.4228e-08) tensor(0.1500)\n",
            "tensor(7.5847e-09) tensor(0.1356)\n",
            "tensor(1.9053e-08) tensor(0.1505)\n",
            "tensor(1.4864e-08) tensor(0.1562)\n",
            "tensor(9.3635e-09) tensor(0.1106)\n",
            "tensor(9.9994e-09) tensor(0.1290)\n",
            "tensor(1.7081e-08) tensor(0.1415)\n",
            "tensor(1.9193e-08) tensor(0.1119)\n",
            "tensor(1.2977e-08) tensor(0.1253)\n",
            "tensor(1.4302e-08) tensor(0.1456)\n",
            "tensor(2.2379e-08) tensor(0.1707)\n",
            "tensor(1.2394e-08) tensor(0.1485)\n",
            "tensor(1.7892e-08) tensor(0.1207)\n",
            "tensor(1.3824e-08) tensor(0.1398)\n",
            "tensor(-1.0288e-09) tensor(0.1248)\n",
            "tensor(9.8621e-09) tensor(0.1455)\n",
            "tensor(9.7268e-09) tensor(0.1696)\n",
            "tensor(8.2467e-09) tensor(0.1608)\n",
            "tensor(1.1041e-08) tensor(0.1400)\n",
            "tensor(1.2368e-08) tensor(0.1377)\n",
            "tensor(4.1909e-08) tensor(0.1174)\n",
            "tensor(2.8087e-08) tensor(0.1294)\n",
            "tensor(2.2750e-08) tensor(0.1611)\n",
            "tensor(1.2026e-08) tensor(0.1552)\n",
            "tensor(8.5753e-09) tensor(0.1510)\n",
            "tensor(5.2382e-09) tensor(0.1478)\n",
            "tensor(9.5815e-09) tensor(0.1591)\n",
            "tensor(1.2006e-08) tensor(0.1561)\n",
            "tensor(1.1917e-08) tensor(0.1296)\n",
            "tensor(1.3095e-08) tensor(0.1179)\n",
            "tensor(1.4914e-08) tensor(0.1318)\n",
            "tensor(1.2846e-08) tensor(0.1376)\n",
            "tensor(1.5321e-08) tensor(0.1356)\n",
            "tensor(1.8928e-08) tensor(0.1202)\n",
            "tensor(8.3351e-09) tensor(0.1187)\n",
            "tensor(1.5574e-08) tensor(0.1503)\n",
            "tensor(9.7312e-09) tensor(0.1252)\n",
            "tensor(2.1701e-08) tensor(0.1377)\n",
            "tensor(1.9754e-08) tensor(0.1289)\n",
            "tensor(4.7209e-10) tensor(0.1226)\n",
            "tensor(1.1621e-08) tensor(0.1475)\n",
            "tensor(1.3891e-08) tensor(0.1353)\n",
            "tensor(6.5093e-09) tensor(0.1549)\n",
            "tensor(4.5468e-09) tensor(0.1093)\n",
            "tensor(2.1445e-08) tensor(0.1551)\n",
            "tensor(1.2241e-08) tensor(0.1192)\n",
            "tensor(4.2349e-09) tensor(0.1172)\n",
            "tensor(1.9406e-08) tensor(0.1401)\n",
            "tensor(1.8908e-08) tensor(0.1340)\n",
            "tensor(1.0373e-08) tensor(0.1072)\n",
            "tensor(1.5484e-08) tensor(0.1161)\n",
            "tensor(9.4442e-09) tensor(0.1109)\n",
            "tensor(2.3023e-10) tensor(0.1057)\n",
            "tensor(1.8915e-08) tensor(0.1414)\n",
            "tensor(1.3386e-08) tensor(0.1404)\n",
            "tensor(1.1714e-08) tensor(0.1172)\n",
            "tensor(1.8536e-08) tensor(0.1531)\n",
            "tensor(3.7111e-08) tensor(0.1290)\n",
            "tensor(1.5551e-08) tensor(0.1591)\n",
            "tensor(5.5115e-09) tensor(0.1276)\n",
            "tensor(9.3005e-09) tensor(0.1221)\n",
            "tensor(1.0009e-08) tensor(0.1363)\n",
            "tensor(1.0155e-08) tensor(0.1627)\n",
            "tensor(5.7237e-09) tensor(0.1241)\n",
            "tensor(1.2104e-08) tensor(0.1253)\n",
            "tensor(5.3769e-09) tensor(0.1439)\n",
            "tensor(5.5574e-09) tensor(0.1316)\n",
            "tensor(1.0713e-08) tensor(0.1480)\n",
            "tensor(1.3751e-08) tensor(0.1354)\n",
            "tensor(1.5554e-08) tensor(0.1479)\n",
            "tensor(1.3076e-08) tensor(0.1533)\n",
            "tensor(5.5549e-09) tensor(0.1353)\n",
            "tensor(3.1367e-09) tensor(0.1303)\n",
            "tensor(1.7862e-08) tensor(0.1437)\n",
            "tensor(3.8155e-09) tensor(0.1229)\n",
            "tensor(1.3134e-08) tensor(0.1425)\n",
            "tensor(1.3211e-08) tensor(0.1331)\n",
            "tensor(5.5808e-09) tensor(0.1441)\n",
            "tensor(1.4068e-08) tensor(0.1401)\n",
            "tensor(8.9454e-09) tensor(0.1344)\n",
            "tensor(9.6471e-09) tensor(0.1493)\n",
            "tensor(1.0402e-08) tensor(0.1339)\n",
            "tensor(1.3566e-08) tensor(0.1351)\n",
            "tensor(4.0719e-09) tensor(0.1484)\n",
            "tensor(8.5946e-09) tensor(0.1508)\n",
            "tensor(2.2148e-08) tensor(0.1325)\n",
            "tensor(1.3352e-08) tensor(0.1520)\n",
            "tensor(1.3042e-08) tensor(0.1523)\n",
            "tensor(4.7923e-09) tensor(0.1390)\n",
            "tensor(5.9603e-09) tensor(0.1345)\n",
            "tensor(2.2007e-08) tensor(0.1354)\n",
            "tensor(7.8415e-09) tensor(0.1383)\n",
            "tensor(3.4191e-08) tensor(0.1461)\n",
            "tensor(4.8398e-09) tensor(0.1578)\n",
            "tensor(1.1524e-08) tensor(0.1326)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-psGH5eN6Vg0",
        "outputId": "87492904-9d62-43db-f9cc-57be51aa07ba"
      },
      "source": [
        "# loss after training\n",
        "model.forward(train_x[:32], train_y[:32])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.1509)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGakSGQqDc4p"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ye023wz2fv0Q",
        "outputId": "91373831-b576-47c3-fbb4-38efef7b2bb8"
      },
      "source": [
        "model.forward(valid_x, valid_y)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.6338)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4awxiCLpgs0"
      },
      "source": [
        "pred = model.loss.log_softmax(model.loss.yhat)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk6O6M2YDeE_"
      },
      "source": [
        "class Fscore():\n",
        "    def __init__(self, inp, trg):\n",
        "        self.inp, self.trg = inp.max(-1).indices, trg.max(-1).indices\n",
        "        self.c = inp.shape[1]\n",
        "    def __call__(self, alpha = 0.5):\n",
        "        self.precision()\n",
        "        self.recall()\n",
        "        f1 = map(\n",
        "            self.fscore, self.tot_pre, self.tot_rec\n",
        "            )\n",
        "        return self.tot_pre, self.tot_rec, list(f1)\n",
        "    def fscore(self, x, y):\n",
        "        return (2*x*y)/(x+y)\n",
        "    \n",
        "    def precision(self):\n",
        "        self.tot_pre= []\n",
        "        for i in range(self.c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.inp ==i\n",
        "            if not sum(denom)==0: self.tot_pre += [sum(numer) / sum(denom)]\n",
        "            else: self.tot_pre += [0.]\n",
        "\n",
        "    def recall(self):\n",
        "        self.tot_rec= []\n",
        "        for i in range(self.c):\n",
        "            numer = self.inp == self.trg\n",
        "            denom = self.trg ==i\n",
        "            if not sum(denom)==0: self.tot_rec += [sum(numer) / sum(denom)]\n",
        "            else: self.tot_rec += [0.]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJUJxDaasgRu",
        "outputId": "70fd12ef-2624-4735-ae11-01f6ce992a9a"
      },
      "source": [
        "measure = Fscore(pred, valid_y)\n",
        "p, r, f = measure()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7 7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8fdhJEldm30",
        "outputId": "ea626e28-a255-4570-d0b9-d7cdce9c0aa7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "p, r, f"
      ],
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([tensor(0.1315), 0.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n",
              " [tensor(1.),\n",
              "  tensor(0.8830),\n",
              "  tensor(0.9042),\n",
              "  tensor(0.9497),\n",
              "  tensor(0.9152),\n",
              "  tensor(0.9438),\n",
              "  tensor(0.8629)],\n",
              " [tensor(0.2325),\n",
              "  tensor(0.),\n",
              "  tensor(0.),\n",
              "  tensor(0.),\n",
              "  tensor(0.),\n",
              "  tensor(0.),\n",
              "  tensor(0.)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovqVJsTsbQlW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}