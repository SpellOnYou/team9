# -*- coding: utf-8 -*-
"""2021-07-various-experiment-tl-rule-driven.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IQ_gLqf6kQBdffgCBikSAR8UguT4YI2s
"""

from fastai.text.all import *
from collections import Counter
from pathlib import Path
from nltk.tokenize import word_tokenize, sent_tokenize
import pandas as pd
from typing import *
import gc

data_path = Path('/content/CLab21/datasets/occ/rule-driven')
train_path = data_path/'train_occ_rule.csv'
valid_path = data_path/'valid_occ_rule.csv'
test_path = data_path/'test_occ_rule.csv'
# get data
get_df = lambda x: pd.read_csv(x, index_col=0)
train_tmp_df = get_df(train_path)

# train_tmp_df.columns

# len(train_tmp_df)

from sklearn.naive_bayes import MultinomialNB
from sklearn.feature_extraction.text import TfidfVectorizer
# Equivalent to CountVectorizer followed by TfidfTransformer.
import operator
from sklearn.metrics import classification_report as f1_metric

from itertools import combinations, product, chain

occ_data = ['tense', 'osp']
occ_rule = ['tense', 'direction', 'over-polarity']
features = list(list(combinations(occ_features, i+1)) for i, _ in enumerate(occ_features))

train_df, valid_df, test_df = map(get_df, (train_path, valid_path, test_path))
train_df = train_df.append(valid_df)
vectorizer = TfidfVectorizer()

def get_combined(train_df, test_df):
    for feature_r in features:
        for feature_comb in feature_r:
            cols = list(feature_comb) + ['text']
            print(cols)
            train_df['combined'] = train_df[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)
            test_df['combined'] = test_df[cols].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)
            yield train_df['combined'], test_df['combined']

dls = TextDataLoaders.from_df(train_df, text_col=['text'], label_col='label', bs=32)
# learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)

def lstm_aws(t_df, v_df, features):
    for feature_r in features:
        for feature_comb in feature_r:
            cols = list(feature_comb) + ['text']
            print(cols)
            dls = TextDataLoaders.from_df(t_df, text_col=cols, label_col='label', bs=32)
            learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5)
            learn.fine_tune(1, 1e-2)
            lr_new = learn.lr_find().valley
            learn.fine_tune(1, lr_new)

            v_df['combined'] = v_df[cols].apply(lambda row: ' '.join(row.values.astype(str)), axis=1)

            ref_dict = {'anger': 0, 'disgust': 1, 'fear': 2, 'guilt': 3, 'joy': 4, 'sadness': 5, 'shame': 6}
            yhat_list = []
            for text in v_df['combined']:
                yhat_list.append(learn.predict(text))

            get_idx = lambda x: ref_dict[x]

            ytrue_list = list(map(get_idx, v_df['label'].tolist()))
            print(v_df['label'].tolist())
            print(f1_metric(ytrue_list, yhat_list, target_names=ref_dict.keys()))

lstm_aws(train_df, test_df, occ_data)
lstm_aws(train_df, test_df, occ_rule)
